[{"title":"【数据库】如何保障数据库和缓存一致性","path":"/2025/03/27/【数据库】如何保障数据库和缓存一致性/","content":"数据库和缓存的一致性问题，在面试以及实践中都是非常重要的知识点，而一般面试者只能说出最佳的实践是什么（即延迟双删或者先更新数据库再删除缓存key），但是不能通过线程之间的读写关系举例说明为什么要这样实践，本文通过穷尽更新缓存的四种方式进行分析，得出了这个结论。最后，本文还介绍了利用消息中间件MQ应对其他更复杂的情形。 [建议先看思维导图和How的总结] Why缓存？ 缓存合理使用确提升了系统的吞吐量和稳定性，然而这是有代价的。这个代价便是缓存和数据库的一致性带来了挑战，本文将针对最常见的 cache-aside 策略下如何维护缓存一致性彻底讲透。 在真实的业务场景中，我们的业务的数据——例如订单、会员、支付等——都是持久化到数据库中的，因为数据库能有很好的事务保证、持久化保证。但是，正因为数据库要能够满足这么多优秀的功能特性，使得数据库在设计上通常难以兼顾到性能，因此往往不能满足大型流量下的性能要求，像是 MySQL 数据库只能承担“千”这个级别的 QPS，否则很可能会不稳定，进而导致整个系统的故障。 但是客观上，我们的业务规模很可能要求着更高的 QPS，有些业务的规模本身就非常大，也有些业务会遇到一些流量高峰，比如电商会遇到大促的情况。 而这时候大部分的流量实际上都是读请求，而且大部分数据也是没有那么多变化的，如热门商品信息、微博的内容等常见数据就是如此。此时，缓存就是我们应对此类场景的利器。 所谓缓存，实际上就是用空间换时间，准确地说是用更高速的空间来换时间，从而整体上提升读的性能。 何为更高速的空间呢？ 更快的存储介质。通常情况下，如果说数据库的速度慢，就得用更快的存储组件去替代它，目前最常见的就是 Redis（内存存储）。Redis 单实例的读 QPS 可以高达 10w&#x2F;s，90% 的场景下只需要正确使用 Redis 就能应对。 就近使用本地内存。就像 CPU 也有高速缓存一样，缓存也可以分为一级缓存、二级缓存。即便 Redis 本身性能已经足够高了，但访问一次 Redis 毕竟也需要一次网络 IO，而使用本地内存无疑有更快的速度。不过单机的内存是十分有限的，所以这种一级缓存只能存储非常少量的数据，通常是最热点的那些 key 对应的数据。这就相当于额外消耗宝贵的服务内存去换取高速的读取性能。 Challenges？引入缓存后的一致性挑战 用空间换时间，意味着数据同时存在于多个空间。最常见的场景就是数据同时存在于 Redis 与 MySQL 上（为了问题的普适性，后面举例中若没有特别说明，缓存均指 Redis 缓存）。 实际上，最权威最全的数据还是在 MySQL 里的。而万一 Redis 数据没有得到及时的更新（例如数据库更新了没更新到 Redis），就出现了数据不一致。 大部分情况下，只要使用了缓存，就必然会有不一致的情况出现，只是说这个不一致的时间窗口是否能做到足够的小。有些不合理的设计可能会导致数据持续不一致，这是我们需要改善设计去避免的。 这里的一致性实际上对于本地缓存也是同理的，例如数据库更新后没有及时更新本地缓存，也是有一致性问题的，下文统一以 Redis 缓存作为引子讲述，实际上处理本地缓存原理基本一致。 缓存不一致性无法客观地完全消灭 为什么我们几乎没办法做到缓存和数据库之间的强一致呢？ 理想情况下，我们需要在数据库更新完后把对应的最新数据同步到缓存中，以便在读请求的时候能读到新的数据而不是旧的数据（脏数据）。但是很可惜，由于数据库和 Redis 之间是没有事务保证的，所以我们无法确保写入数据库成功后，写入 Redis 也是一定成功的；即便 Redis 写入能成功，在数据库写入成功后到 Redis 写入成功前的这段时间里，Redis 数据也肯定是和 MySQL 不一致的。如下两图所示： 无法事务保持一致 所以说这个时间窗口是没办法完全消灭的，除非我们付出极大的代价，使用分布式事务等各种手段去维持强一致，但是这样会使得系统的整体性能大幅度下降，甚至比不用缓存还慢，这样不就与我们使用缓存的目标背道而驰了吗？ 不过虽然无法做到强一致，但是我们能做到的是缓存与数据库达到最终一致，而且不一致的时间窗口我们能做到尽可能短，按照经验来说，如果能将时间优化到 1ms 之内，这个一致性问题带来的影响我们就可以忽略不计。 How更新缓存?引言 通常情况下，我们在处理查询请求的时候，使用缓存的逻辑如下： 1234567data = queryDataRedis(key);if (data ==null) &#123; data = queryDataMySQL(key); //缓存查询不到，从MySQL做查询 if (data!=null) &#123; updateRedis(key, data);//查询完数据后更新MySQL最新数据到Redis &#125;&#125; 也就是说优先查询缓存，查询不到才查询数据库。如果这时候数据库查到数据了，就将缓存的数据进行更新。这是我们常说的 cache aside 的策略，也是最常用的策略。 这样的逻辑是正确的，而一致性的问题一般不来源于此，而是出现在处理写请求的时候。所以我们简化成最简单的写请求的逻辑，此时你可能会面临多个选择，究竟是直接更新缓存，还是失效缓存？而无论是更新缓存还是失效缓存，都可以选择在更新数据库之前，还是之后操作。 这样就演变出 4 个策略：更新数据库后更新缓存、更新数据库前更新缓存、更新数据库后删除缓存、更新数据库前删除缓存。下面我们来分别讲述。 1. 更新数据库后更新缓存的不一致问题一种常见的操作是，设置一个过期时间，让写请求以数据库为准，过期后，读请求同步数据库中的最新数据给缓存。那么在加入了过期时间后，是否就不会有问题了呢？并不是这样。 大家设想一下这样的场景。 假如这里有一个计数器，把数据库自减 1，原始数据库数据是 100，同时有两个写请求申请计数减一，假设线程 A 先减数据库成功，线程 B 后减数据库成功。那么这时候数据库的值是 98，缓存里正确的值应该也要是 98。 但是特殊场景下，你可能会遇到这样的情况： 线程 A 和线程 B 同时更新这个数据。 更新数据库的顺序是先 A 后 B。 更新缓存时顺序是先 B 后 A。 如果我们的代码逻辑还是更新数据库后立刻更新缓存的数据，那么—— 12updateMySQL();updateRedis(key, data); 就可能出现：数据库的值是 100-&gt;99-&gt;98，但是缓存的数据却是 100-&gt;98-&gt;99，也就是数据库与缓存的不一致。而且这个不一致只能等到下一次数据库更新或者缓存失效才可能修复。 时间线程A（写请求）线程B（写请求）问题T1更新数据库为99T2更新数据库为98T3更新缓存数据为98T4更新缓存数据为99此时缓存的值被显式更新为99，但是实际上数据库的值已经是98，数据不一致 当然，如果更新 Redis 本身是失败的话，两边的值固然也是不一致的，这个前文也阐述过，几乎无法根除。 2. 更新数据库前更新缓存的不一致问题那你可能会想，这是否表示，我应该先让缓存更新，之后再去更新数据库呢？类似这样： 12updateRedis(key, data);//先更新缓存updateMySQL();//再更新数据库 这样操作产生的问题更是显而易见的，因为我们无法保证数据库的更新成功，万一数据库更新失败了，你缓存的数据就不只是脏数据，而是错误数据了。 你可能会想，是否我在更新数据库失败的时候做 Redis 回滚的操作能够解决呢？这其实也是不靠谱的，因为我们也不能保证这个回滚的操作 100% 被成功执行。 同时，在写写并发的场景下，同样有类似的一致性问题，请看以下情况： 线程 A 和线程 B 同时更新同这个数据。 更新缓存的顺序是先 A 后 B。 更新数据库的顺序是先 B 后 A。 举个例子。线程 A 希望把计数器置为 0，线程 B 希望置为 1。而按照以上场景，缓存确实被设置为 1，但数据库却被设置为 0。 所以通常情况下，更新缓存再更新数据库是我们应该避免使用的一种手段。 3. 更新数据库前删除缓存的问题那如果采取删除缓存的策略呢？也就是说我们在更新数据库的时候失效对应的缓存，让缓存在下次触发读请求时进行更新，是否会更好呢？同样地，针对在更新数据库前和数据库后这两个删除时机，我们来比较下其差异。 最直观的做法，我们可能会先让缓存失效，然后去更新数据库，代码逻辑如下： 12deleteRedis(key);//先删除缓存让缓存失效updateMySQL();//再更新数据库 这样的逻辑看似没有问题，毕竟删除缓存后即便数据库更新失败了，也只是缓存上没有数据而已。然后并发两个写请求过来，无论怎么样的执行顺序，缓存最后的值也都是会被删除的，也就是说在并发写写的请求下这样的处理是没问题的。 然而，这种处理在读写并发的场景下却存在着隐患。 还是刚刚更新计数的例子。例如现在缓存的数据是 100，数据库也是 100，这时候需要对此计数减 1，减成功后，数据库应该是 99。如果这之后触发读请求，缓存如果有效的话，里面应该也要被更新为 99 才是正确的。 那么思考下这样的请求情况： 线程 A 更新这个数据的同时，线程 B 读取这个数据。 线程 A 成功删除了缓存里的老数据，这时候线程 B 查询数据发现缓存失效。 线程 A 更新数据库成功。 时间线程A（写请求）线程B（读请求）问题T1删除缓存值T21.读取缓存数据，缓存缺失，从数据库读取数据100T3更新数据库中的数据X的值为99T4将数据100的值写入缓存此时缓存的值被显式更新为100，但是实际上数据库的值已经是99了 可以看到，在读写并发的场景下，一样会有不一致的问题。 针对这种场景，有个做法是所谓的“延迟双删策略”，就是说，既然可能因为读请求把一个旧的值又写回去，那么我在写请求处理完之后，等到差不多的时间延迟再重新删除这个缓存值。 时间线程A（写请求）线程C（新的读请求）线程D（新的读请求）问题T5sleep(N)缓存存在，读取到缓存旧值100其他线程可能在双删成功前读到脏数据T6删除缓存值T7缓存缺失，从数据库读取数据的最新值（99） 这种解决思路的关键在于对 N 的时间的判断，如果 N 时间太短，线程 A 第二次删除缓存的时间依旧早于线程 B 把脏数据写回缓存的时间，那么相当于做了无用功。而 N 如果设置得太长，那么在触发双删之前，新请求看到的都是脏数据。 4. 更新数据库后删除缓存那如果我们把更新数据库放在删除缓存之前呢，问题是否解决？我们继续从读写并发的场景看下去，有没有类似的问题。 时间线程A（写请求）线程B（读请求）线程C（读请求）潜在问题T1更新主库 X = 99（原值 X = 100）T2读取数据，查询到缓存还有数据，返回100线程C实际上读取到了和数据库不一致的数据T3删除缓存T4查询缓存，缓存缺失，查询数据库得到当前值99T5将99写入缓存 可以看到，大体上，采取先更新数据库再删除缓存的策略是没有问题的，仅在更新数据库成功到缓存删除之间的时间差内——[T2,T3)的窗口 ，可能会被别的线程读取到老值。 而在开篇的时候我们说过，缓存不一致性的问题无法在客观上完全消灭，因为我们无法保证数据库和缓存的操作是一个事务里的，而我们能做到的只是尽量缩短不一致的时间窗口。 在更新数据库后删除缓存这个场景下，不一致窗口仅仅是 T2 到 T3 的时间，内网状态下通常不过 1ms，在大部分业务场景下我们都可以忽略不计。因为大部分情况下一个用户的请求很难能再 1ms 内快速发起第二次。 但是真实场景下，还是会有一个情况存在不一致的可能性，这个场景是读线程发现缓存不存在，于是读写并发时，读线程回写进去老值。并发情况如下： 时间线程A（写请求）线程B（读请求--缓存不存在场景）潜在问题T1查询缓存，缓存缺失，查询数据库得到当前值100T2更新主库 X = 99（原值 X = 100）T3删除缓存T4将100写入缓存此时缓存的值被显式更新为100，但是实际上数据库的值已经是99了 总的来说，这个不一致场景出现条件非常严格，因为并发量很大时，缓存不太可能不存在；如果并发很大，而缓存真的不存在，那么很可能是这时的写场景很多，因为写场景会删除缓存。 所以待会我们会提到，写场景很多时候实际上并不适合采取删除策略。 总结 【总结】红字为相应的解决方案，但是这些方案或多或少都存在一些问题： 分布式锁：操作重 用MQ确认：复杂 延迟双删：关键在于sleep(N)的N 太短：早于新的读请求，于是新的读请求请求了数据库又往缓存写入了脏数据，无用功 太长：新的读请求都得到了脏数据 【总结】最佳实践：更新数据库后删除缓存值 读多写少–&gt;更新数据库后删除缓存 读写相当&#x2F;写多读少–&gt;更新数据库后更新缓存 【原总结，看完上面的还没理解可以往下看】终上所述，我们对比了四个更新缓存的手段，做一个总结对比，其中应对方案也提供参考，具体不做展开，如下表： 策略并发场景潜在问题应对方案更新数据库+更新缓存写+读线程A未更新完缓存之前，线程B的读请求会短暂读到旧值可以忽略写+写更新数据库的顺序是先A后B，但更新缓存时顺序是先B后A，数据库和缓存数据不一致分布式锁（操作重）更新缓存+更新数据库无并发线程A还未更新完缓存但是更新数据库可能失败利用MQ确认数据库更新成功（较复杂）写+写更新缓存的顺序是先A后B，但更新数据库时顺序是先B后A分布式锁（操作很重）删除缓存值+更新数据库写+读写请求的线程A删除了缓存在更新数据库之前，这时候读请求线程B到来，因为缓存缺失，则把当前数据读取出来放到缓存，而后线程A更新成功了数据库延迟双删（但是延迟的时间不好估计，且延迟的过程中依旧有不一致的时间窗口）更新数据库+删除缓存值写+读（缓存命中）线程A完成数据库更新成功后，尚未删除缓存，线程B有并发读请求会读到旧的脏数据可以忽略写+读（缓存不命中）读请求不命中缓存，写请求处理完之后读请求才回写缓存，此时缓存不一致分布式锁（操作重） 从一致性的角度来看，采取更新数据库后删除缓存值，是更为适合的策略。因为出现不一致的场景的条件更为苛刻，概率相比其他方案更低。 那么是否更新缓存这个策略就一无是处呢？不是的！ 删除缓存值意味着对应的 Key 会失效，那么这时候读请求都会打到数据库。如果这个数据的写操作非常频繁，就会导致缓存的作用变得非常小。而如果这时候某些 Key 还是非常大的热 Key，就可能因为扛不住数据量而导致系统不可用。 如下图所示： 删除策略频繁的缓存失效导致读请求无法利用缓存 所以做个简单总结，足以适应绝大部分的互联网开发场景的决策： 针对大部分读多写少场景，建议选择更新数据库后删除缓存的策略。 针对读写相当或者写多读少的场景，建议选择更新数据库后更新缓存的策略。 最终一致性如何保证？–&gt;缓存设置过期时间 第一个方法便是我们上面提到的，当我们无法确定 MySQL 更新完成后，缓存的更新&#x2F;删除一定能成功，例如 Redis 挂了导致写入失败了，或者当时网络出现故障，更常见的是服务当时刚好发生重启了，没有执行这一步的代码。 这些时候 MySQL 的数据就无法刷到 Redis 了。为了避免这种不一致性永久存在，使用缓存的时候，我们必须要给缓存设置一个过期时间，例如 1 分钟，这样即使出现了更新 Redis 失败的极端场景，不一致的时间窗口最多也只是 1 分钟。 这是我们最终一致性的兜底方案，万一出现任何情况的不一致问题，最后都能通过缓存失效后重新查询数据库，然后回写到缓存，来做到缓存与数据库的最终一致。 Addition:消息中间件的运用 如何减少缓存删除&#x2F;更新的失败？万一删除缓存这一步因为服务重启没有执行，或者 Redis 临时不可用导致删除缓存失败了，就会有一个较长的时间（缓存的剩余过期时间）是数据不一致的。 那我们有没有什么手段来减少这种不一致的情况出现呢？这时候借助一个可靠的消息中间件就是一个不错的选择。 因为消息中间件有 ATLEAST-ONCE 的机制，如下图所示。 我们把删除 Redis 的请求以消费 MQ 消息的手段去失效对应的 Key 值，如果 Redis 真的存在异常导致无法删除成功，我们依旧可以依靠 MQ 的重试机制来让最终 Redis 对应的 Key 失效。 而你们或许会问，极端场景下，是否存在更新数据库后 MQ 消息没发送成功，或者没机会发送出去机器就重启的情况？ 这个场景的确比较麻烦，如果 MQ 使用的是 RocketMQ，我们可以借助 RocketMQ 的事务消息，来让删除缓存的消息最终一定发送出去。而如果你没有使用 RocketMQ，或者你使用的消息中间件并没有事务消息的特性，则可以采取消息表的方式让更新数据库和发送消息一起成功。事实上这个话题比较大了，我们不在这里展开。 如何处理复杂的多缓存场景？有些时候，真实的缓存场景并不是数据库中的一个记录对应一个 Key 这么简单，有可能一个数据库记录的更新会牵扯到多个 Key 的更新。还有另外一个场景是，更新不同的数据库的记录时可能需要更新同一个 Key 值，这常见于一些 App 首页数据的缓存。 我们以一个数据库记录对应多个 Key 的场景来举例。 假如系统设计上我们缓存了一个粉丝的主页信息、主播打赏榜 TOP10 的粉丝、单日 TOP 100 的粉丝等多个信息。如果这个粉丝注销了，或者这个粉丝触发了打赏的行为，上面多个 Key 可能都需要更新。只是一个打赏的记录，你可能就要做： 1234updateMySQL();//更新数据库一条记录deleteRedisKey1();//失效主页信息的缓存updateRedisKey2();//更新打赏榜TOP10deleteRedisKey3();//更新单日打赏榜TOP100 这就涉及多个 Redis 的操作，每一步都可能失败，影响到后面的更新。甚至从系统设计上，更新数据库可能是单独的一个服务，而这几个不同的 Key 的缓存维护却在不同的 3 个微服务中，这就大大增加了系统的复杂度和提高了缓存操作失败的可能性。最可怕的是，操作更新记录的地方很大概率不只在一个业务逻辑中，而是散发在系统各个零散的位置。 针对这个场景，解决方案和上文提到的保证最终一致性的操作一样，就是把更新缓存的操作以 MQ 消息的方式发送出去，由不同的系统或者专门的一个系统进行订阅，而做聚合的操作。如下图： 不同业务系统订阅 MQ 消息单独维护各自的缓存 Key 通过订阅 MySQL binlog 的方式处理缓存上面讲到的 MQ 处理方式需要业务代码里面显式地发送 MQ 消息。还有一种优雅的方式便是订阅 MySQL 的 binlog，监听数据的真实变化情况以处理相关的缓存。 例如刚刚提到的例子中，如果粉丝又触发打赏了，这时候我们利用 binlog 表监听是能及时发现的，发现后就能集中处理了，而且无论是在什么系统什么位置去更新数据，都能做到集中处理。 目前业界类似的产品有 Canal，具体的操作图如下： 利用 Canel 订阅数据库 binlog 变更从而发出 MQ 消息，让一个专门消费者服务维护所有相关 Key 的缓存操作 到这里，针对大型系统缓存设计如何保证最终一致性，我们已经从策略、场景、操作方案等角度进行了细致的讲述，希望能对你起到帮助。 参考资料：一文讲透数据库缓存一致性问题 (qq.com) 扩展学习： 为什么Redis快？ 消息中间件的ATLEAST-ONCE是什么机制？ 如何更新数据库和发送MQ一起成功，事务消息是什么？消息表又是什么？ 数据库有哪些log？分别是什么作用？"},{"title":"【Kubernetes】如何搭建Kubenetes集群","path":"/2025/03/24/【Kubernetes】如何搭建Kubenetes集群/","content":"本文将使用kubeadm模式快速部署一主两从集群。 虚拟机准备首先本地需要准备：CentOS7.x-86_x64镜像，硬件至少2GB。 然后打开VMware WorkStation新建三个虚拟机（新建虚拟机教程，可以选择基础设施服务器），分别命名为master、node1、node2。 接下来确保虚拟机能够访问外网（注意宿主机不要连校园网），采用NAT模式，操作如下： 检查宿主机的适配器VMnet8的ip网段：cmd中执行ipconfig，VMnet8的ip要和外网处于同一网段 如果不在同一个网段，则手动配置VMnet8的ip和掩码 检查虚拟机：虚拟网络编辑器的NAT设置是否网段一致，手动配置 修改/etc/sysconfig/network-scripts/ifcfg-ens33文件，配置虚拟机网断、掩码、网关、DNS 使之生效：systemctl restart network 重启网络服务 （如果failed看解决 Linux 网络 “Job for network.service failed because the control process exite”） ping网关 192.168.43.2可以，ping百度 www.baidu.com可以，完成！ 系统准备"},{"title":"【Go基础】分布式事务","path":"/2025/03/23/【Go基础】分布式事务/","content":"从几个缩写讲起首先，提到事务，一般指的是数据库的事务，指逻辑上的一组操作，要么都执行，要么都不执行。 ACID，指的是数据库在写入或者更新资料时，为了保证交易正确可靠，要具备的4个特性： 缩写 英文单词 中文解释 说明 A atomicity 原子性 最小执行单位，all or nothing C consistency 一致性 执行前后一致 I isolation 隔离性 并发时，事务间不干扰 D durability 持久性 持久改变 这里要特别注意，C一致性是最终的目的，其余三个是实现C的手段。在单机上实现ACID可以通过锁、时间序列等机制。 接下来是分布式事务，与微服务密切相关，因为不同的微服务一般会使用自己的数据库，这个时候要满足ACID就比较困难了，如何保证系统中多个相关联的数据库中的数据一致？ 此时，需要选择折中的方案，为此，引进了CAP理论： 缩写 英文单词 中文解释 说明 C consistency 一致性 所有节点访问同份最新数据副本，要么返回最新数据要么失败 A availability 可用性 非故障节点在合理时间返回合理响应，不保证数据一致 P partition tolerance 分区容忍性 出现网络分区时仍对外提供服务 分布式系统必须保障能够对外提供服务，即分区容错性是必须的。不可能三角指的是在读写操作时，假设出现了网络分区，只能满足两个，即CP或者AP。这里要特别注意，如果没有出现网络分区，A和C是可以同时满足的。当数据不一致会影响业务时，选择CP，当业务需要高可用时，选择AP。常用的注册中心中，Zookeeper保证了CP，Eureka保证了AP，Nacos二者都支持。 在C和A的权衡实践中，诞生了BASE理论： 缩写 英文单词 中文解释 说明 B basically available 基本可用性 允许损失部分可用性（响应时间延长，损失部分非核心功能等） A availability 可用性 S soft-state 软状态 允许数据不一致，不影响整体可用性 E eventually consistent 最终一致性 一致的三个级别 这里需要理清一致性的3个级别： 强一致性：在银行等场景需要保证； 弱一致性：什么时候达到一致的状态完全没有保证（所以基本不用）； 最终一致性：系统保证在一定时间内达到一致，业界比较推崇，那么如何保证最终一致性： 读时修复 写时修复（性能好） 定期修复（常用） 分布式事务的解决方案在分布式系统中，如何保障各个节点之间的ACID特性？主要解决方案可分为两大类： 1. 强一致性方案 二阶段提交协议（2PC） 三阶段提交协议（3PC） 2. 最终一致性方案 补偿事务（TCC） MQ事务 Saga事务 本地消息表 其中： 2PC、3PC 属于业务代码无侵入方案，基于 XA 规范衍生而来。 TCC、Saga 属于业务入侵方案，需要开发者手动实现补偿逻辑。 MQ 事务依赖于消息队列，本地消息表不支持回滚。 强一致性方案（2PC &amp; 3PC）根据XA规范设计，首先介绍XA规范涉及的角色： 其中，AP表示应用程序本身，RM表示资源管理器（一般就是数据库）、TM表示事务管理器。 AP（Application Program）：应用程序 RM（Resource Manager）：资源管理器（通常指数据库） TM（Transaction Manager）：事务管理器 2PC（两阶段提交） 准备阶段（Prepare） TM 向所有 RM 发送事务请求。 RM 执行事务但 不提交，仅写入日志并锁定资源。 提交阶段（Commit） 若所有 RM 均准备成功，TM 通知 RM 提交事务。 若有失败，则 TM 让所有 RM 回滚事务。 问题： 阻塞问题：等待提交时，资源被锁定。 单点故障：如果 TM 宕机，可能导致事务卡住。 3PC（三阶段提交）对 2PC 进行了改进，增加了超时机制。 CanCommit（准备阶段） TM 询问 RM 是否可提交事务。 RM 返回 Yes &#x2F; No &#x2F; 超时。 PreCommit（预提交阶段） 若所有 RM 均返回 Yes，TM 发送预提交请求。 RM 预执行事务，等待最终确认。 若有 RM 失败或超时，则 TM 发送中断请求。 DoCommit（提交阶段） 若所有 RM 均完成预提交，TM 发送最终提交请求。 进入该阶段后，基本不会失败。 改进点： 增加超时机制，避免事务永久阻塞。 通过 CanCommit 阶段减少资源长时间锁定。但是解决并不完美，性能差、数据仍然不一致，应用不广泛，一般会通过复制状态机解决2PC的阻塞问题。 最终一致性方案（TCC &amp; Saga &amp; MQ &amp; 本地消息表）TCC（Try-Confirm-Cancel）适用于高并发、低延迟的业务场景，例如支付系统。 Try（尝试执行）：进行业务检查，预留资源。 Confirm（确认执行）：若所有 Try 操作成功，则正式提交。 Cancel（取消执行）：若某个 Try 失败，则执行回滚操作。 注意： 需要业务开发者自己实现 Try、Confirm、Cancel 逻辑。 Confirm 失败时一般会重试，最终仍失败则需人工介入。 MQ 事务基于 两阶段提交，适用于 事件驱动架构。 发送半消息，等待本地事务执行。 本地事务执行成功，则确认发送消息；失败则回滚消息。 事务反查机制：检查消息是否成功发送。 消息消费失败时，消息队列会自动进行重试，超过最大次数进入 死信队列，等待人工处理。 特点： 适用于 跨系统事务（如支付完成后通知订单系统）。 异步处理，吞吐量高，但不保证强一致性。 Saga 事务适用于 长事务（如电商订单流程：支付 → 发货 → 确认收货）。 将事务拆分为 多个子事务，每个子事务执行完即提交。 若某个子事务失败，则触发 补偿事务 进行回滚。 Saga 事务没有预留资源，不保证隔离性。 Seata 是典型的 Saga 事务实现。 问题： 需要业务开发者自己编写补偿逻辑。 若补偿失败，则需人工介入。 本地消息表适用于 保证可靠消息的场景。 事务执行时，先写入数据库本地消息表。 定时扫描消息表，将消息投递到 MQ。 缺点：不支持事务回滚，需额外补偿机制。 方案对比总结 方案 业务代码侵入性 适用场景 关键特性 2PC 无侵入 传统数据库事务 强一致性，阻塞问题 3PC 无侵入 分布式数据库事务 改进 2PC，仍有不一致风险 TCC 需要开发者实现 高并发业务，如金融支付 高性能，需要 Try-Confirm-Cancel Saga 需要开发者实现 长事务，如订单流程 适用于多步骤事务，无隔离性 MQ 事务 依赖 MQ 事件驱动架构 事务解耦，不保证 ACID 本地消息表 依赖数据库 可靠消息 无法回滚，需要补偿 总结： 强一致性：2PC &#x2F; 3PC，适用于对事务要求极高的场景。 最终一致性：TCC &#x2F; Saga &#x2F; MQ &#x2F; 本地消息表，适用于高吞吐量或长事务。 TCC &#x2F; Saga 需要开发者手动管理事务，2PC &#x2F; 3PC 由事务管理器自动处理。 选择哪种方案，取决于业务需求、性能要求以及对一致性的容忍度。 &#x2F;&#x2F; 待补充学习 补充：分布式系统的开发中，延迟是个很重要的指标。评估服务可用性–&gt;负载均衡和容灾；评估领导者节点可用性–&gt;是否发起领导选举。 —某天职场老兵William突然抽查我的八股基础，回来赶紧灰溜溜补上……"},{"title":"【技术思考】工程上的最佳实践","path":"/2025/03/23/【技术思考】工程上的最佳实践/","content":"正式进入工作岗位之前对精进技术的思考——工程上的最佳实践 Why？首先要理解为什么要从工程实践的角度思考，常规的培训教程虽然是以项目的形式，但目的是帮助我们学会使用基本的开发工具如何使用，而实际开发过程中如何将各种技术组件有效地组合和应用、如何解决实际的业务问题，则是进一步需要关注的问题。 How？以原有的点评项目为例进行思考，可以考虑各部分设计的原因，能否优化： 消息中间件：思考使用场景，如订单状态更新、用户评价通知等，分析为什么要使用消息中间件，以及如何设计消息的生产、消费和存储。 缓存：考虑缓存的使用场景，如热门商品信息缓存、用户会话缓存等，分析如何识别并处理热key，以及缓存的更新和失效策略。 数据库设计与优化：审视数据库表的设计是否合理，是否符合业务需求，以及如何通过索引优化、查询优化等手段提升数据库性能。 微服务架构：分析拆分是否合理，服务之间的依赖关系是否清晰，服务降级、熔断和负载均衡策略是否有效。 服务上线：如何上线，例如灰度发布中的流量染色，如何保证服务的高可用性。 以微服务为例进行思考，考虑从调用和原理到设计决策的转变： 之前学习时，重点可能放在了如何调用中间件以及它们的底层原理上。 现在需要将重心转移到：在给定业务场景下，为什么要这样设计这些组件。 例如，微服务的负载均衡、服务发现、降级熔断等模块，不仅要清楚它们的作用，更要结合业务场景思考如何拆分微服务，以及制定相应的服务降级、熔断和负载均衡策略。以分布式事务为例，虽然有TCC、二阶段提交等理论方案，但在实际开发中，这些方案的严格实现需要很多条件支持，如数据库的兼容性、业务操作的反向接口等。在实际生产中，接口可能无法完美支持这些理论方案，这时需要考虑其他方法，如对账机制，来保证最终一致性，尤其是在对强一致性要求不高的业务场景中。以对账机制的工程实践为例，可能在实现最终一致性的时间间隔上较长，但其泛用性广且易于实现，设计对账机制需要考虑如何在业务执行频率较低时进行对照，以及如何处理幂等性等问题。 在上述思考过程中，可以借鉴大众点评、美团外卖、饿了么、滴滴等成熟项目的技术文章，了解它们在工程实践中的经验和教训。思路放宽，例如，各大应用基本都有点赞模块，了解它们是如何实现的，筛选出和自己的项目比较贴合的部分深入研究。 例如，大众点评在订单系统分库分表实践中的垂直切分和水平切分策略，以及如何通过Hash切分实现数据的均匀分布和易于扩展的架构。 DDD在大众点评交易系统演进中的应用 2-大众点评内容平台架构实践-三木 大众点评订单系统分库分表实践 了解了实践中的技术原理之后，再进一步关注通用方法论的提炼： 第一个是基础架构平台层面。例如，分布式ID发号器（如Leaf）、热Key检测与治理、大文件分布式对象存储（如JFS）等，理解这些通用实践，为自己的项目提供参考和借鉴，提升解决实际问题的能力。 第二个是思想层面。例如，在无法控制仓库报送数据的情况下，通过数据分析确定需要特殊处理的仓库，采用简单粗暴但有效的硬编码方式解决问题。此处提炼的方法论是：当技术手段难以直接解决问题时，可以通过分析实际数据和业务场景，找到变通的非技术性方法来绕过技术难题。 以上为主线任务，接下来是支线任务，即提前了解部门技术栈和业务后，例如云原生相关可以了解： Kubernetes稳定性保障实践 AutoMQ官方账号 —-与职场老兵William的对话整理"},{"title":"【通用工具】Git分布式版本控制工具","path":"/2025/03/21/【通用工具】Git分布式版本控制工具/","content":"Git有两个基本作用: 版本控制 团队开发 一、Git工作流程 二、Git基本配置设置用户信息设置：（+如果要查看，只输入双引号前面的就好了） 12git config --global user.name &quot;yourname&quot;git config --global user.email &quot;youremail&quot; 有3种范围：--local只对某个仓库有效，--global对当前用户的所有仓库有效，--system对系统所有登录的用户有效。 要显示config的配置，加--list。 三、Git基本使用获取本地仓库git init，执行之后工作目录下就会产生.git隐藏目录。 核心操作 clone（克隆）: 从远程仓库中克隆代码到本地仓库 checkout （检出）:从本地仓库中检出一个仓库分支然后进行修订 add（添加）: 在提交前先将代码提交到暂存区 可以接单个文件名，也可以接通配符 commit（提交）: 暂存区 –&gt; 本地仓库。本地仓库中保存修改的各个历史版本 可以接-m后跟注释 fetch (抓取) ： 从远程库，抓取到本地仓库，不进行任何的合并动作，一般操作比较少 pull (拉取) ： 从远程库拉到本地库，自动进行合并(merge)，然后放到到工作区，相当于fetch+merge push（推送） : 修改完成后，需要和团队成员共享代码时，将代码推送到远程仓库 辅助查看与操作 git status：查看修改的状态 git log [option]：查看提交日志，git-log以精简形式查看 git log：以默认形式查看提交日志 git log --all：显示所有分支的提交日志 git log --pretty=oneline：将提交信息显示为一行 git log --abbrev-commit：使得输出的 commitId 更简短 git log --graph：以图的形式显示提交历史，便于查看分支合并情况 git reflog commitID：记录所有操作，可以回滚到任意地方 git reset --hard commitID：版本回退 添加文件到忽略列表：创建 .gitignore 文件，列出要忽略的文件模式 回滚如果在开发过程中，某个需求不需要了，此时分为3种情况讨论： 文件在工作区：执行git checkout file 文件在暂存区：执行git reset HEAD file，让这个文件回到工作区，然后执行1 文件在本地仓库：执行git reset -方式（有3种） hard：工作区、暂存区、本地仓库3个地方保持一致 mixed：让文件保存在工作区 soft：让文件保存在暂存区 四、Git分支核心操作 查看本地分支：git branch 创建本地分支：git branch 分支名 切换分支：git checkout 分支名 可以直接切换到一个不存在的分支（创建并切换）：git checkout -b 分支名 合并分支：git merge 分支名称，一个分支上的提交可以合并到另一个分支 删除分支：不能删除当前分支，只能删除其他分支 git branch -d b1 删除分支时，需要做各种检查 git branch -D b1 不做任何检查，强制删除 解决冲突步骤： 处理文件中冲突的地方 将解决完冲突的文件加入暂存区(add) 提交到仓库(commit) GitFlow master （生产） 分支：线上分支，主分支，中小规模项目作为线上运行的应用对应的分支； develop（开发）分支：是从master创建的分支，一般作为开发部门的主要开发分支，如果没有其他并行开发不同期上线要求，都可以在此版本进行开发，阶段开发完成后，需要是合并到master分支,准备上线； feature/xxxx分支：从develop创建的分支，一般是同期并行开发，但不同期上线时创建的分支，分支上的研发任务完成后合并到develop分支； hotfix/xxxx分支：从master派生的分支，一般作为线上bug修复使用，修复完成后需要合并到master、test、develop分支； 还有一些其他分支，在此不再详述，例如test分支（用于代码测试）、pre分支（预上线分支）等等。 五、Git远程仓库基本命令 对接远程仓库： git remote add &lt;远端名称&gt; &lt;仓库路径&gt; 查看远程仓库： git remote 推送到远程仓库：git push [-f] [--set-upstream] [远端名称 [本地分支名]:[远端分支名]] 如果远程分支名和本地分支名称相同，则可以只写本地分支git push origin master -f 表示强制覆盖 --set-upstream 推送到远端的同时并且建立起和远端分支的关联关系 如果当前分支已经和远端分支关联，则可以省略分支名和远端名 查看本地分支与远程分支的关联关系：git branch -vv 从远程仓库克隆：git clone &lt;仓库路径&gt; [本地目录] 从远程仓库抓取&#x2F;拉取：（如果不指定远端名称和分支名，就抓取所有分支） git fetch [remote name] [branch name]：将仓库里的更新都抓取到本地，不进行合并。 git pull [remote name] [branch name]：将远端仓库的修改拉到本地并自动进行合并，等同于fetch+merge 解决冲突远程分支也是分支，解决冲突的方式和本地相同（看上文）。 需要先拉取远程仓库的提交，经过合并后才能推送到远端分支： 六、进阶命令交互式变基在本地使用，重新排序、合并、拆分、编辑或删除提交，从而整理提交历史，使其更加清晰。 rebase和merge的区别：都是实现合并分支，但是细节不同，rebase会把复杂的提交历史修订为干净整洁的线性结构，并且产生新的commitID。 使用步骤： 执行git rebase -i HEAD~5，此时打开一个编辑器，显示最近的5个提交，每个提交前有一个命令（默认是pick） 编辑提交列表，修改每一行前面的命令，例如pick改成reword Git会按照指令提交 常用命令： 命令 缩写 作用 pick p 保留该提交（不做修改） reword r 修改提交信息 edit e 暂停 rebase，允许修改提交内容（如增删文件）或提交信息 squash s 合并到前一个提交，并保留提交信息 fixup f 合并到前一个提交，但丢弃当前提交的提交信息 drop d 删除该提交 exec x 执行一个 shell 命令（如运行测试） 注意事项： 不要修改已经推送到远程仓库的提交历史（除非确定没有其他人基于此工作） 如果遇到冲突： 解决冲突后，用 git add 标记为已解决 继续 rebase：git rebase --continue 或终止 rebase：git rebase --abort 解决后强制推送到远程：git push --force 储藏 临时保存未提交的更改，将当前工作目录和暂存区的修改保存到一个“储藏区”（stash stack），可以快速切换分支或处理其他任务，后续再恢复这些更改。 基本命令： 基本命令 具体操作 说明 存（入栈） stash (push) 默认存入当前工作区的修改到栈中 stash save &quot;注释&quot; 可以连续存多次变动代码，添加注释方便区分 取（出栈） stash pop 取出栈顶的修改并应用到当前工作区，同时从栈中移除该修改 注意：确保此时 pop 的变动代码是你需要的，否则 pop 后可能需要重新压栈 stash apply 取出栈顶的修改并应用到当前工作区，但不从栈中移除该修改（类似 peek） 清除 stash drop 丢弃栈顶的修改 stash clear 清空整个 stash 栈 查看 stash list 查看 stash 栈中的所有修改记录 stash show + 栈索引 查看指定索引位置的修改详情 使用场景： 切换分支时，当前分支有未完成的代码。 需要紧急修复其他分支的 Bug，但不想提交当前代码。 临时保存实验性代码，避免污染提交历史。 合并冲突前，先保存当前改动。 使用示例： 12345678910111213141516# 1. 当前有未提交的修改，但需要切换到其他分支git stash# 2. 切换到其他分支并完成任务git checkout other-branch# ... 处理其他任务 ...# 3. 返回原分支并恢复储藏git checkout original-branchgit stash pop # 恢复并删除最近的储藏# 4. 查看储藏列表（可选）git stash list# 5. 清空储藏（可选）git stash clear 挑选工作在多分支结构的提交维度上，与merge的区别： merge：需要另一个分支上的所有变动 cherry-pick：需要另一个分支上的部分变动 提交情形： 当产生冲突时，会停下来让用户决定，此时有3种情况： --continue：解决冲突后，git add，再执行此命令继续合并 --abort：放弃合并，回到之前的状态 --quit：放弃合并，且不回到之前 比较不同diff命令，主要讲解两点提交和三点提交的区别： 七、铁令 切换分支前先提交本地的修改 代码及时提交，提交过了就不会丢 遇到任何问题都不要删除文件目录"},{"title":"【Go基础】常用环境变量设置","path":"/2025/03/19/【Go基础】常用环境变量设置/","content":"常用环境变量GOROOT： go的安装目录（go安装：https://golang.google.cn/dl/） GOPATH：一般给文件夹起名叫GoWorkstation、Go_WorkSpace等。 src：存放源代码 pkg：存放依赖包 bin：存放可执行文件 其他常用环境变量：GOOS，GOARCH，GOPROXY国内用户建议设置 goproxy：export GOPROXY&#x3D;https://goproxy.cn"},{"title":"【Go基础】错误处理","path":"/2025/03/19/【Go基础】错误处理/","content":"基本认识 在Go中，将错误当成值来进行处理，强调判断错误和处理错误，不支持try/catch捕获异常。 Go选择使用Error而非Exception来进行错误处理。 一般把错误作为函数或方法的最后一个返回值。 Error接口使用error接口表示错误类型。该接口只有一个Error()方法，返回描述错误信息的字符串。 123type error interface &#123; Error() string&#125; 接口类型的默认零值为nil，所以通常把调用函数时返回的错误和nil比较： 12345_, err := someFunc(some parameters)if err != nil&#123; fmt.Println(&quot;出现错误：&quot;, err) // 使用标准库fmt打印错误自动调用error类型的Error方法，打印错误描述信息 return&#125; Go这种机制的好处是，遇到error需要立即处理，而Java中是try/catch中包裹了一大堆代码，良性和致命的问题都会抛出错误，不容易排查问题。 创建错误由于error是接口，可以自定义错误类型（开发中间件使用较多）。 最简单的创建错误的方法是用errors包提供的New函数创建一个错误： 123func New(text string) error&#123; return &amp;errorString&#123;text&#125;\t// 返回一个指针，使得每次返回都是一个新的对象，否则在做等值判断时可能会出问题。&#125; 错误的两种类型error：可以被处理的错误；panic：非常严重不可恢复的错误。 errors包当需要传入格式化的错误描述信息，用fmt.Errorf更好，但是它提供很多描述错误的文本信息，会丢失原本的错误类型，导致错误在做等值判断时失效。为了解决这个缺陷，fmt.Errorf在1.13版本提供了特殊的格式化动词w%，可以基于已有错误再包装得到新的错误： 1fmt.Errorf(&quot;查询数据库失败，err:%w&quot;, err) 对于这种二次包装的错误，errors包提供了4个常用的方法： New：创建一个新的 error func Is(err, target error) bool ：判断err是否包含target，是不是特定的某个error func As(err error, target interface&#123;&#125;) bool：判断error是否为target类型，类型转换为特定的error（用得不多） func Unwrap(err error) error：获得error包含下一层错误，解除包装并返回被包装的 error 使用举例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport (\t&quot;errors&quot;\t&quot;fmt&quot;)func main() &#123;\tvar err error = &amp;MyError&#123;&#125;\tprintln(err.Error())\tErrorsPkg()&#125;type MyError struct &#123;&#125;func (m *MyError) Error() string &#123;\treturn &quot;Hello, it&#x27;s my error&quot;&#125;func ErrorsPkg() &#123;\terr := &amp;MyError&#123;&#125;\t// 使用 %w 占位符，返回的是一个新错误\t// wrappedErr 是一个新类型，fmt.wrapError\twrappedErr := fmt.Errorf(&quot;this is an wrapped error %w&quot;, err)\t// 再解出来\tif err == errors.Unwrap(wrappedErr) &#123; fmt.Println(&quot;unwrapped&quot;)\t&#125; if errors.Is(wrappedErr, err) &#123; // 虽然被包了一下，但是 Is 会逐层解除包装，判断是不是该错误 fmt.Println(&quot;wrapped is err&quot;)\t&#125;\tcopyErr := &amp;MyError&#123;&#125;\t// 这里尝试将 wrappedErr转换为 MyError\t// 注意我们使用了两次的取地址符号\tif errors.As(wrappedErr, &amp;copyErr) &#123; fmt.Println(&quot;convert error&quot;)\t&#125;&#125; panic意味着fatal error，调用者不能解决，彻底结束。可能遇到的场景： 调用别人的代码，别人没有合理使用panic（自己写代码还是用error）。 数组越界、不可恢复的环境、栈溢出等错误。 从panic中恢复： ​\trecover可以进行兜底，把这一次的request放弃，go的runtime会退出，可以去执行其他的request，但是风险比较大，revover一般就是记录个日志之类的，，示例： 123456789101112131415package mainimport &quot;fmt&quot;func main() &#123;\tdefer func() &#123; if data := recover(); data != nil &#123; fmt.Printf(&quot;hello, panic: %v &quot;, data) &#125; fmt.Println(&quot;恢复之后从这里继续执行&quot;)\t&#125;()\tpanic(&quot;Boom&quot;)\tfmt.Println(&quot;这里将不会执行下来&quot;)&#125; 使用原则 遇事不决选 error 当怀疑可以用 error 的时候，就说明不需要 panic 一般情况下，只有快速失败的过程，才会考虑panic defer用于在方法返回之前执行某些动作（类似于Java中的finally），一般用来释放资源（如锁等）。执行顺序：像栈一样，先进后出。 处理错误正常流程的代码推荐的写法，err处理缩进，正常的代码是一条直线。 12345678910111213/////////推荐写法////////f, err := os.Open(path)if err != nil &#123; // handle error&#125;// do stuff//////////不推荐///////f, err := os.Open(path)if err == nil &#123; // do stuff&#125;// handle error 少写if err !&#x3D; nil的技巧 返回err或者nil，可以直接return： 12345678910111213//////原来的写法func AuthenticateRequest(r *Request) error &#123; err := authenticate(r.User) if err != nil &#123; return err &#125; return nil&#125;//////推荐的写法 //毕竟函数的返回值就要error类型，而且调用函数之后就返回一个error类型，那直接return就好了func AuthenticateRequest(r *Request) error &#123; return authenticate(r.User)&#125; 用io.Reader统计读取内容的行数 1234567891011121314151617181920212223242526272829//////原来的写法func CountLines(r io.Reader) (int, error) &#123; var ( br = bufio.NewReader(r) lines int err error ) for &#123; _, err = br.ReadString(&#x27; &#x27;) lines++ if err != nil &#123; break &#125; &#125; if err != io.EOF &#123; return 0, err &#125; return lines, nil&#125;//////推荐的写法 //func CountLines(r io.Reader) (int, error) &#123; sc := bufio.NewScanner(r) lines := 0 for sc.Scan() &#123; lines++ &#125; return lines, sc.Err()&#125; 利用bufio.Scanner方法，这个里面封装了按行读取的逻辑，并且其Scan方法读取时遇到错误会记录下来，最终通过 sc.Err()统一返回。 包装错误类型，缓存错误 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758////////////原来的写法type Header struct &#123; Key, Value string&#125;type Status struct &#123; Code int Reason string&#125;func WriteResponse(w io.Writer, st Status, headers []Header, body io.Reader) error &#123; _, err := fmt.Fprintf(w, &quot;HTTP/1.1 %d %s\\r &quot;, st.Code, st.Reason) if err != nil &#123; return err &#125; for _, h := range headers &#123; _, err := fmt.Fprintf(w, &quot;%s: %s\\r &quot;, h.Key, h.Value) if err != nil &#123; return err &#125; &#125; if _, err := fmt.Fprintf(w, &quot;\\r &quot;); err != nil &#123; return err &#125; _, err = io.Copy(w, body) return err&#125;//////////////推荐的写法 //type errWriter struct &#123; io.Writer err error\t// 用来暂存&#125;func (e *errWriter) Write(buf []byte) (int, error) &#123; if e.err != nil &#123; return 0, e.err &#125; var n int n, e.err = e.Writer.Write(buf) return n, e.err&#125;func WriteResponse(w io.Writer, st Status, headers []Header, body io.Reader) error &#123; ew := &amp;errWriter&#123;Writer: w&#125; fmt.Fprintf(ew, &quot;HTTP/1.1 %d %s\\r &quot;, st.Code, st.Reason) for _, h := range headers &#123; fmt.Fprintf(ew, &quot;%s: %s\\r &quot;, h.Key, h.Value) &#125; fmt.Fprintf(ew, &quot;\\r &quot;) io.Copy(ew, body) return ew.err&#125; 下面这种写法，不用做任何err的判定，相当于在包装类里面复用了，更优雅。 使用errors包装错误-从根本上解决上一小节只是减少了if err !&#x3D; nil的数量，但是并没有从根本上解决不能提供详细上下文的问题。一方面，破坏原始错误，担心上层调用的人用做等值判定，只能一层层向上透传，最终输出没有堆栈没有上下文的信息，令人崩溃；另一方面，又想包装更多详细错误信息。 error.Wrap()：保留原始错误信息，捎带一些附加信息。 errors.Cause()：用来获取原始错误（根因，root error）。 errors.WithMessage()：不保存堆栈信息。 实际应用时： 自己的应用代码中，使用errors.New()或者errors.Errorf()返回错误； 如果调用其他包内的函数，直接返回，往上抛，不要在错误的地方到处打日志。（满足原则：只处理一次。） 如果使用三方库&#x2F;标准库，使用errors.Wrap()或errors.Wrapf()保存堆栈信息。 程序的顶部或者工作的goroutine顶部，用%+v详细记录堆栈。 处理错误的原则处理的原则是：如果遇到错误，只处理一次。 一些经常出现的错误代码，在错误处理中，既记录了日志，又返回了错误： 12345678func WriteAll(w io.Writer, buf []byte) error &#123; _, err := w.Write(buf) if err != nil &#123; log.Println(&quot;unable to write:&quot;, err) return err &#125; return nil&#125; 这个时候又尬住了，一方面，不记录日志，找不到是谁报错；另一方面，记录日志接下来调用者层层打印，在控制台的输出可能就层层割裂，没有完整的堆栈信息。 继续讲处理的原则：错误处理契约规定，出现错误时，不能对其他返回值的内容做任何假设。如果程序员忘记return，函数返回的结果可能是正确的，但是其他返回值的内容是错误的。 那么应该如何记录日志？原则： 错误要被日志记录 *应用程序处理错误，保证**100%*完整性 之后不再报告当前错误 结合上一小节，包装错误的原则： 如果你提供的库很多人使用，不应该使用任何wrap包装错误 如果你的函数无法处理错误，携带足够多的上下文，用wrap.Errors往上抛（足够的上下文：能帮助解决问题，一般是什么人调用了什么接口，返回成功还是失败） 如果这个错误被处理过，就不要再抛了。 【参考资料】 https://www.liwenzhou.com/posts/Go/error/"},{"title":"【Go基础】并发编程基本概念","path":"/2025/03/19/【Go基础】并发编程基本概念/","content":"并发编程基本概念串行、并发与并行 串行：我们都是先读小学，小学毕业后再读初中，读完初中再读高中。 并发：同一时间段内执行多个任务（你在用微信和两个女朋友聊天）。 并行：同一时刻执行多个任务（你和你朋友都在用微信和女朋友聊天）。 进程、线程和协程 进程（process）：程序在操作系统中的一次执行过程，系统进行资源分配和调度的一个独立单位。 线程（thread）：操作系统基于进程开启的轻量级进程，是操作系统调度执行的最小单位。 协程（coroutine）：非操作系统提供而是由用户自行创建和控制的用户态‘线程’，比线程更轻量级。 并发模型4种常见的实现方式： 线程&amp;锁模型 Actor模型 CSP模型（communicating sequential processes，Go中主要是基于CSP的goroutine和channel实现） Fork&amp;Join模型"},{"title":"【Go基础】垃圾回收演进 三色标记法","path":"/2025/03/19/【Go基础】垃圾回收演进三色标记法/","content":"GO1.3标记清除，整体需要STW：1.暂停，找到可达和不可达对象，2. 标记可达对象，3. 清除未标记对象，4. 结束暂停 GO1.5三色标记法，堆启动写屏障，栈不启动，全部扫描一次后，需要重新扫描栈（STW），效率低 如果没有STW，对象丢失的2个条件： 黑色对象指向白色对象（白色挂在黑色下面） 灰色对象与其可达白色对象之间遭到破坏（灰色也丢失了该白色） 屏障机制，保障对象不丢失的2种方式： 强三色不变式：不允许黑色对象指向白色对象 弱三色不变式：允许黑色对象指向白色对象，但是该白色对象要被灰色对象可达 为此，go初步得到两种屏障方式： 插入写屏障：只使用在堆中，将黑色指向的白色对象标记为灰色；栈要启动STW重新三色标记扫描（仍然需要STW重新扫描栈） 删除写屏障：被删除的白色节点标记为灰色（保护灰色对象到白色对象的路径不会断），所以最后一个指向它的指针也依旧可以活过这一轮，在下一轮GC中被清理掉（回收精度低，开始时STW记录初始快照） 为什么在栈中不使用： GO1.8三色标记法，混合写屏障，栈不启动，堆启动，几乎不需要STW，效率高 结合得到混合写屏障（满足弱三色不变）： 开始时将所有栈上的可达节点标记为黑色，在GC期间栈上新增的也标记为黑色（无需STW） 删除和新增的全部标记为灰色 参考资料： https://www.bilibili.com/video/BV1wz4y1y7Kd/"},{"title":"【Go基础】Go入门与实践资源帖","path":"/2025/03/19/【Go基础】Go入门与实践资源帖/","content":"看到好的持续更新…… Go系统教程 从语法讲起：李文周博客 七天快速上手项目 Go测试驱动开发博客 孔令飞项目开发实战课程，孔令飞图文教程 《Go 语言高级编程》书籍 Go算法刷题模板 Go实战项目 KV系统 crawlab分布式爬虫平台 seaweedfs分布式文件系统 Cloudreve云盘系统 gfast后台管理系统（基于Go Frame） alist多存储文件列表（基于Gin、React） Yearning开源SQL审核平台 Go要点 GMP机制 并发编程机制 编辑解释运行机制 GC机制 看过的帖子 腾讯技术工程：协程调度的本质 通用技术面试相关 极客时间面试指导视频课"},{"title":"【Go基础】微服务概念与演进","path":"/2025/03/19/【Go基础】微服务概念与演进/","content":"微服务概念与演进巨石架构到微服务的演进传统网页应用虽然进行了模块化设计，但是最终仍然是打包成一个war包进行部署，启动慢，无法拓展，可靠性很低。 什么是微服务是面向服务的架构模式（SOA）的最佳实践。定义：围绕业务功能构建的，服务关注单一业务，服务间采用轻量级的通信机制，可以全自动独立部署，可以使用不同的编程语言和数据存储技术。微服务架构通过业务拆分实现服务组件化，通过组件组合快速开发系统，业务单一的服务组件又可以独立部署，使得整个系统变得清晰灵活。 如何实现微服务组件服务化，例如在Go中实现需要：• kit：一个微服务的基础库（框架）• service：业务代码 + kit 依赖 + 第三方依赖组成的业务微服务• RPC + message queue：轻量级通讯按业务组织服务，常见的模式：大前端（移动&#x2F;Web） &gt; 网关接入 &gt; 业务服务 &gt; 平台服务 &gt; 基础设施（PaaS&#x2F;Saas） 微服务的优点和缺点优点：原子服务、独立进程、隔离部署、去中心化服务治理。 缺点：基础设施的建设、复杂度高。固有的复杂性：① 必须使用RPC或者消息传递实现进程间的通信，处理通信慢与局部失效的问题；② 不同服务可能使用不同数据库。 要搞定这些缺点，需要做怎样的基础设施建设做什么事情–可用性设计、API设计等引申话题 微服务组件微服务设计中常见的角色三大组件：API Gateway、BFF层、底层服务Microservices。API网关分层： 流量入口：协议转换&#x2F;路由分发 安全边界：统一认证&#x2F;权限控制 流量治理：限流熔断&#x2F;日志监控 BFF适配层：为不同终端提供定制化APICQRS模式：读写分离（通过binlog实现数据同步） 演进过程Microservices拆分: 按垂直功能性能角度，含久必分分久必合 可以考虑中间加一层(例如统一接入账号) 按照业务领域抽象（DDD） 按照功能拆分：CQRS，应用程序分为命令端和查询端。 安全问题外部的安全保障：API Gateway统一认证拦截 -&gt; BFF校验Token -&gt; Service 服务内部的安全保障：① 认证：知道是谁调用的；② 授权：RBAC，控制能访问哪些接口。 信任等级：Full&#x2F;Half&#x2F;Zero Trust。 gRPC概念A high-performance, open-source universal RPC framework. 高性能开源框架。特性： 支持多语言； 序列化支持Protocol Buffer和Json； HTTP&#x2F;2多路复用。 其中最重要的是标准健康监测协议，应用如下：应用1：服务稳定与不稳定时摘除与恢复；应用2：外挂容器健康检测；应用3：生产者与消费者之间的检测；应用4：平滑发布。 服务发现的模型① 客户端发现（微服务的核心是去中心化，用这种更好）；② 服务端发现（如果服务很大，可能用service mesh）。 多集群与多租户多集群why?——单集群坏处：一般布N+2来冗余节点。出现故障时后果严重。how?——物理上两套资源，逻辑上维护cluster概念。好处？——不同集群使用多套独占的缓存，性能好。坏处？——缓存命中率下降，不同业务形态数据正交。拓展：从全集群中选取一批节点（子集），利用划分子集限制连接池大小。——子集算法。 多租户why？保障代码隔离性，基于流量租户做路由决策。问题：[并行测试]时混用环境不可靠，而多布环境成本高，也难以做压测。解决方法：染色发布，基于流量类型做路由。本质是从源头传递一个标签，挂在go的上下文中，基于RPC负载均衡的流量做路由,路由到指定的节点。 参考资料：https://microservices.io/index.htmlhttps://blog.csdn.net/mindfloating/article/details/51221780https://www.cnblogs.com/dadadechengzi/p/9373069.htmlhttps://www.cnblogs.com/viaiu/archive/2018/11/24/10011376.htmlhttps://www.cnblogs.com/lfs2640666960/p/9543096.htmlhttps://mp.weixin.qq.com/s/L6OKJK1ev1FyVDu03CQ0OAhttps://www.bookstack.cn/read/API-design-guide/API-design-guide-02-面向资源的设计.mdhttps://www.programmableweb.com/news/how-to-design-great-apis-api-first-design-and-raml/how-to/2015/07/10http://www.dockone.io/article/394https://www.jianshu.com/p/3c7a0e81451ahttps://www.jianshu.com/p/6e539caf662dhttps://my.oschina.net/CraneHe/blog/70317https://my.oschina.net/CraneHe/blog/703169https://my.oschina.net/CraneHe/blog/703160 学习笔记，侵删。"},{"title":"【LeeCode】刷题记录.md","path":"/2024/04/08/【LeeCode】刷题记录/","content":"作者：力扣官方题解 来源：力扣（LeetCode） LeeCode热题10049、字母异位词分组（中）https://leetcode.cn/problems/group-anagrams/solutions/520469/zi-mu-yi-wei-ci-fen-zu-by-leetcode-solut-gyoc/ 题面给你一个字符串数组，请你将 字母异位词 组合在一起。可以按任意顺序返回结果列表。 字母异位词 是由重新排列源单词的所有字母得到的一个新单词。 为什么是哈希表相关的题？ 思路： 当把单词中所有字母按照字母顺序表排列时，字母异位词的排序后的单词是相同的。 可以使用相同点作为一组字母异位词的标志，使用哈希表存储每一组字母异位词。 哈希表的键为一组字母异位词的标志，哈希表的值为一组字母异位词列表。 具体做法：遍历每个字符串，对于每个字符串，得到该字符串所在的一组字母异位词的标志，将当前字符串加入该组字母异位词的列表中。遍历全部字符串之后，哈希表中的每个键值对即为一组字母异位词。 方法1：字母排序 构造单词的字符排序，作为键。 将单词加入散列表。 返回答案。 1234567891011121314class Solution &#123; public List&lt;List&lt;String&gt;&gt; groupAnagrams(String[] strs) &#123; Map&lt;String, List&lt;String&gt;&gt; map = new HashMap&lt;String, List&lt;String&gt;&gt;(); for (String str : strs) &#123; char[] array = str.toCharArray(); Arrays.sort(array); String key = new String(array); List&lt;String&gt; list = map.getOrDefault(key, new ArrayList&lt;String&gt;()); list.add(str); map.put(key, list); &#125; return new ArrayList&lt;List&lt;String&gt;&gt;(map.values()); &#125;&#125; 复习 char[] toCharArray() 。将此字符串转换为新的字符数组。 getOrDefault。HashMap的一个方法，返回指定键映射到的值，如果此映射不包含键的映射，则返回 defaultValue 。 向list中新增元素用add方法。 向哈希表中新增元素用put方法，同时传入键和值。 复杂度分析 方法2：计数 互为字母异位词的两个字符串包含的字母相同，因此两个字符串中的相同字母出现的次数一定是相同的，故可以将每个字母出现的次数使用字符串表示，作为哈希表的键。 字符串只包含小写字母，因此对于每个字符串，可以使用长度为 26 的数组记录每个字母出现的次数。 首先统计字符的出现顺序，然后构造键，把具有相通特征的字符串的单词们放在一组，最后返回结果。 12345678910111213141516171819202122232425class Solution &#123; public List&lt;List&lt;String&gt;&gt; groupAnagrams(String[] strs) &#123; Map&lt;String, List&lt;String&gt;&gt; map = new HashMap&lt;String, List&lt;String&gt;&gt;(); for (String str : strs) &#123; int[] counts = new int[26]; int length = str.length(); for (int i = 0; i &lt; length; i++) &#123; counts[str.charAt(i) - &#x27;a&#x27;]++; &#125; // 将每个出现次数大于 0 的字母和出现次数按顺序拼接成字符串，作为哈希表的键 StringBuffer sb = new StringBuffer(); //可变字符串对象 for (int i = 0; i &lt; 26; i++) &#123; if (counts[i] != 0) &#123; sb.append((char) (&#x27;a&#x27; + i)); sb.append(counts[i]); &#125; &#125; String key = sb.toString(); List&lt;String&gt; list = map.getOrDefault(key, new ArrayList&lt;String&gt;()); list.add(str); map.put(key, list); &#125; return new ArrayList&lt;List&lt;String&gt;&gt;(map.values()); &#125;&#125; 复杂度分析 面试要点 通过分析，能否意识到单词和键的映射关系。 利用散列表高效储存结果。 数据结构和常见的库函数。"},{"title":"【资源帖】学习Java和算法","path":"/2024/04/06/【资源帖】学习Java和算法/","content":"Java教程学习路线【黑马程序员】 Java简版基础教程：https://www.bilibili.com/video/BV1Cv411372m/ 书：《Java核心技术 1》 书：《Head First Java》 Java Web框架：https://www.bilibili.com/video/BV1m84y1w7Tb/ 单体项目开发： 苍穹外卖：https://www.bilibili.com/video/BV1TP411v7v6/ 微服务： 全套微服务技术栈：https://www.bilibili.com/video/BV1S142197x7/ 企业级项目实战（选择学习）： 学成在线【在线教育】：https://www.bilibili.com/video/BV1j8411N7Bm/ 黑马头条【企业级微服务项目】 ：https://www.bilibili.com/video/BV1Qs4y1v7x4/ 面试专题： 2023版：https://www.bilibili.com/video/BV1yT411H7YK/ 复制标题和时长：https://www.bilibili.com/read/cv22846057/ 精进指南 （JavaWeb后，选学）MySQL：https://www.bilibili.com/video/BV1Kr4y1i7ru/ （微服务后，选学）Redis微服务：https://www.bilibili.com/video/BV1cr4y1671t/ （微服务后，选学）MybatisPlus：https://www.bilibili.com/video/BV1Xu411A7tL/ （JVM前，必学）计算机网络：https://www.bilibili.com/video/BV1c4411d7jb/ （Java基础，选学）JVM虚拟机：https://www.bilibili.com/video/BV1r94y1b7eS/ （JVM后，选学）并发编程：https://www.bilibili.com/video/BV16J411h7Rd/ （git版本控制，选学）https://www.bilibili.com/video/BV1MU4y1Y7h5/ 资源帖 JavaGuide：JavaGuide（Java学习&amp;面试指南） | JavaGuide JavaBooks：https://gitee.com/itwanger/JavaBooks 拿个offer：拿个offer - 开源&amp;项目实战 (nageoffer.com) LeeCode刷题指南官网力扣 (LeetCode) 全球极客挚爱的技术成长平台 刷题指北peach买个共享会员账号看考察频次。 资源帖 labuladong：本站简介 | labuladong 的算法笔记（提升算法能力。） 代码随想录：代码随想录 (programmercarl.com)（全面，但是精简，适合面试突击。） 小林coding：小林coding (xiaolincoding.com)（图解好理解，但只有Redis、MySQL、计网。） 左程云：左程云的个人空间-左程云个人主页-哔哩哔哩视频 (bilibili.com)（算法讲解。） NeeCode：NeetCode（英文站点。） 推荐书单 《剑指offer》。"},{"title":"【求职】如何写一份受欢迎的校招简历","path":"/2024/04/05/【求职】如何写一份受欢迎的校招简历/","content":"常见问题 过度包装设计。减弱主要信息能量，华而不实。 篇幅过长。 求职定位不明。 实践经历描述不当。 一份简历闯天下。 JD：工作职责、工作胜任力。 使用表格式简历。 啰啰嗦嗦重点不突出。 不该讲的乱讲。例如，创业、离职原因、到岗时间、离婚、错误检讨、薪资条件。 优秀简历的特征版面设计简洁大方、布局清晰、模板分界。 简历结构结构完整、详略得当、易于阅读。 内容呈现逻辑清晰、优势突出、数据支撑。 人岗匹配有的放矢、贴近岗位JD、天生我才。 效果 脱颖而出、入得法眼。 顺畅读完，越读越喜欢。 打动人心，不如见一面。 为面试好印象做好铺垫。（面试官其实是根据初印象，步步求证是否确实是需要的人。） 简历的完整结构“2+2”通用的（非本专业&#x2F;技术岗）： 基本信息：略写。7%。 自我评价：较详。20%。 工作经历：详写。（大力气。）70%。 学历、证书、技能：略写。3%。 基本信息 姓名+求职意向+性别+年龄。（政治面貌：国企央企等写，外企不写，民企无所谓。） 联系方式：城市、电话、微信、邮箱。（不用写太多。城市可以写XX(意向城市)。联系方式三个必有一，推荐电话。） 个人照片：彩色、正面头像、有精气神。（匹配行业。） 自我评价&#x2F;教育背景社招： 工作背景。例如，年份+领域&#x2F;行业+擅长&#x2F;熟悉&#x2F;掌握。 优势能力。四条分号隔开。专业软件可以写。 职业素养。 校招： 起止时段：学校、专业、学历、学位。 主修课程。 奖学金可以写。 工作经历&#x2F;实习经历&#x2F;项目经历社招： 工作时段。（可以有总分，总的在某个公司，分的是不同岗位。最好是倒叙。） 工作职责。（前3-5个。） 工作业绩。（为了醒目，可以换个标志，比如五角星。一定要有数据，没数据也不要乱讲。） 工作获奖。（要有含金量的，行业、省市级以上，发明专利等。） 校招： 起止时段、公司、岗位。 工作职责、价值、奖项。 其他佐证 学历背景：学校、专业。 语言能力：语种、级别。（只是针对某些需要语言能力的岗位。其他：听说读写能力流利，可作为工作语言。） 专业技能：证书、级别。（例如岗位资格证。） 校招和社招的区别 教育背景前置&#x2F;后置。 自我评价的有无。（复盘能力。） 优秀简历写作心法人岗匹配！！！ 职场的本质是价值交换。（以终为始。） 见字如面，格式细节很重要，大小标题和逻辑关系。 凤头猪肚豹尾。自我评价漂亮客观，工作经历饱满有结果，其他佐证简短有力。 工作经历倒叙。写清楚总分，闭环表达，数据支撑。 工作年限5年以下，请用一张A4纸完成。 如果经历比较少，根据一段经历可以多挖掘，例如，“1+3+6+x”主轴。 如何准备 确定自己身份：校招&#x2F;社招，确定目标岗位，了解岗位JD。 准备模板，通读三遍。准备素材，多多益善。（所有经历都可以准备。） 现有骨架，再填充。时间倒叙，先粗后细。 先写草稿，反复打磨。"}]