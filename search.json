[{"title":"【分布式】节点数为什么设置成奇数？","path":"/2025/11/29/【分布式】节点数为什么设置成奇数？/","content":"多数派的定义分布式系统里（比如 Etcd、ZooKeeper、Consul、Redis Sentinel、MongoDB ReplicaSet 等）一般采用多数派原则。 多数派原则（majority）： 只有多数派节点（majority of voting nodes）同意，写入才算成功；只有多数派在线，集群才能选出主节点。少数派分区永远不能参与选举，也不能投票 选举（leader election）和一致性仲裁（quorum）更高效、更可靠。在最少节点的情况下达成最高的可用性。 多数派的定义是： 1quorum = floor(N/2) + 1 多数派选举需要 &gt;50% 的票数 奇数节点能减少浪费的资源 偶数节点不会提高容错能力 奇数节点能避免“平票”（leader 选不出来） 奇数投票节点确保一致性？（1）避免平票，保证能选出 Primary奇数节点让投票在任何情况下都能明确区分“多数派”和“少数派”，而不会出现 50&#x2F;50 的对等分裂，从而避免平票，让 leader 一定能选出来。 主节点选举依赖多数票。示例对比： ✔ 使用 3 个投票节点（奇数）！ 123456节点：A, B, C （3 voting）majority = 2假设 A 挂了：剩下 B、C 仍有 2 票可继续选主 系统仍然 有主节点 → 可继续读写。 ✘ 使用 4 个投票节点（偶数） 12节点：A, B, C, Dmajority = 3 即使挂掉一个： 1剩 3 个节点 → 需要 3 票 → 刚好全部在线 任何一个节点再出现网络抖动： 12只剩 2 票 &lt; majority(3)无法选主 → 集群只读不能写 ➡ 多花了一个节点却不能提升容错能力。 （2）写入确保不会产生“脑裂（split-brain）”写操作要求被多数投票节点确认才能成功： 举例：3 voting nodes → majority &#x3D; 2 1primary 成功写入两个节点 → 数据安全 这样即使 primary 发生故障，另一个节点晋升为 primary 时： 它一定已经拥有最新多数写入的数据 旧主不会带着未提交的数据乱写 ➡ 奇数投票节点保证：只有一个分区能达到 majority，另一个分区不能产生脏写。 （3）最优容错&#x2F;资源比 建议投票节点必须为奇数（3、5、7） 是因为偶数节点没有增加容错能力，纯浪费资源。 节点数 多数派 容忍故障数 说明 3 2 1 常用最小集群 4 3 1 和 3 节点一样，但多浪费一个节点 5 3 2 容错能力提高了 ➡ 所以为了不浪费资源，同样想增加容错能力时，会直接跳到 5 节点，而不是 4 节点。 primary 必须获得多数投票 → 避免选举平票 写操作必须多数节点确认 → 避免多主和脑裂 奇数节点最大化可用性，最小化资源浪费 因此 MongoDB 通过 majority 写入 + 奇数投票节点 + 单主架构 确保副本集中只有一个合法主节点，并且数据是强一致的。 主节点失联 注意：网络分裂是“触发选举”的原因 副本集的节点之间依赖心跳（heartbeat）互相确认是否“能连通”。如果 Primary 无法与多数投票节点通信，它必须自动放弃主节点身份。自动降级（step down）变成 Secondary、不参与选举、不参与投票。 否则：它写的数据无法同步给其他节点，其他节点可能已经选出新的 Primary，两个 “主” 会产生冲突写，破坏一致性。 能连通 &#x3D; 存活节点 不能连通 &#x3D; 故障节点 故障节点 自动被投票系统忽略。只有与大多数节点相互可达的节点才是合法的投票者。选举只发生在多数派分区中。 当主节点恢复，发现已经有新的 Primary，不会争抢主，会自动作为 Secondary 追赶 oplog（同步数据），完全不会参与正在进行的选举。 选举新主节点 Phase 1：请求成为候选人（申请 term） Phase 2：投票 在任何一个 term（选举轮次）里只能有一个候选人。 🚫 他们无法同时成为候选人（协议禁止） 🚫 electionTimeout 随机化让“同时发起”几乎不可能，即使一轮失败，也不会卡住，而是发起下一轮选举投票 🚫 即使同时尝试，term 冲突规则保证只有一个候选人存活 🚫 投票只能投给一个候选人，不能“投给自己”当候选人 Raft 用的是 随机选举超时，每个节点有一个随机 electionTimeout，这个时间到达之前，不会发起选举，所以每轮只有 1 个节点最先到时间。 即使时间因为延迟等原因差不多，Raft 规定节点只能给一个候选人投票。 B 向 C 请求投票 C 向 B 请求投票 两者收到对方的 term 后，会比较 term 大小：谁的 term 更大，另一个就自动放弃本次竞选（step down），票投给 term 更大的那一方。所以最终仍然会选出一个 Primary。这叫 term 冲突决议。 什么情况下会卡住？ 多数派本身断裂：A /断网/ B C，集群仍然正常运行（在 B、C 那一边） 如果分裂成：A B | C，AB都在选自己，C又断网→无法投票，本轮失败 → 下一轮继续随机超时 → 必然选出一个。 有多数派 → 一定能选出来 没多数派 → 协议自动重试，直到选出（除非网络把多数派都断开，否则不会选不出来。） 节点故障和网络分区本质一样，但表现方式不同。 节点故障 &#x3D; 无法与该节点通信 网络分区 &#x3D; 一部分节点无法与另一部分通信 → 从 Raft &#x2F; Paxos &#x2F; Zookeeper 的选主协议视角来看：两者都是“通信不可达”，本质等价。 1. 节点故障属于网络分区的一种特殊情况节点故障有两种典型表现： 节点宕机（进程挂了、机器断电） 节点卡死（CPU 100%，没有响应） 在这两种情况下： 其他节点发 RPC 给它 超时，一直收不到回复 效果 ≈ 这个节点被隔离到了一个别人都到不了的区域 这就是一个非常典型的 “一对多” 网络分区： 12正常区域：A、B、C隔离区域：D（单独一块） 从多数派算法看： D 和大家无法通信 A、B、C 仍然构成多数派，继续运行 所以“节点故障”其实就是“单节点网络分区”。 2. 网络分区不一定是节点故障网络分区可以更复杂，比如： 情况 1：分成 2-2 的两个组（4 节点例子） 1A B | C D 两边互相看不到 每一边都认为另一边“宕机” 但实际上大家都还在，只是通信断了。 情况 2：单链路损坏 123A -- CA X BB -- C A 和 B 互相到不了，但都能到 C。 这不是任何节点故障，只是链路坏了。 3. 多数派协议看的是“能否通信”，不看“为什么无法通信”对于 Raft &#x2F; Paxos &#x2F; ZK 而言： 情况 协议视角 等价吗 节点宕机 收不到心跳 → 不可达 和“单节点分区”完全一样 节点高负载卡死 超时 → 不可达 等价 网络 cable 掉了 不可达 等价 路由异常导致某节点看不到其他节点 不可达 等价 整个机房掉电 大部分节点不可达 等价 所以：对分布式一致性算法来说，“原因不重要”，只看通信结果。 4. 为什么要把它们视为同一种情况？因为共识算法的核心目标是： 保证只有多数派区域能够选主、写数据。 不管是因为： 节点宕机 火灾 网卡坏了 交换机掉线 延迟过高 TCP 拥塞太严重 机器卡死不回包 某段链路丢包 最终的结果都是节点之间无法通信。所以从一致性协议角度： 节点故障”和“网络分区”都是“不可达”。 它们的后果与处理方式完全一样。 拓展问题MongoDB 如何判断一个节点“失联”？（基于心跳、electionTimeout） 投票节点（voting node）和数据节点（non-voting node）的区别？ 如果主节点没有 step down 会怎样？（真实脑裂案例） “网络分裂情况下的时间线”描述一次真实的 MongoDB 选举过程"},{"title":"【mongoDB】分片","path":"/2025/11/28/【mongoDB】分片/","content":"1.实战中的配置查看mongo集群的pod12345678910kubectl get pod -n mongoNAME READY STATUS RESTARTS AGEmongo-mongodb-sharded-configsvr-0 1/1 Running 0 16dmongo-mongodb-sharded-configsvr-1 1/1 Running 1 (16d ago) 16dmongo-mongodb-sharded-configsvr-2 1/1 Running 1 (16d ago) 16dmongo-mongodb-sharded-mongos-0 1/1 Running 0 16dmongo-mongodb-sharded-mongos-1 1/1 Running 0 16dmongo-mongodb-sharded-shard0-data-0 1/1 Running 0 16dmongo-mongodb-sharded-shard0-data-1 1/1 Running 0 16dmongodb-exporter-976c9b7b-8dt25 1/1 Running 0 16d 在 MongoDB 分片架构中： mongos (mongo-mongodb-sharded-mongos-0): 只是路由节点，负责转发请求，不存储任何数据。所以你在它的 describe 结果里只看到了 localtime 和 kube-api-access，看不到数据卷。 configsvr (mongo-mongodb-sharded-configsvr-0): 存储集群的元数据（配置信息）。 shard data (mongo-mongodb-sharded-shard0-data-0): 这才是真正存储数据库业务数据的地方。 想要知道数据实际存储在哪里第一步：查看数据节点 Pod 的 PVC 名称 1kubectl describe pod mongo-mongodb-sharded-shard0-data-0 -n mongo 找到Volumes部分，其中ClaimName就是PVC名字。 12345Volumes: datadir: Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace) ClaimName: datadir-mongo-mongodb-sharded-shard0-data-0 ReadOnly: false 第二步：查看 PVC 对应的 PV 名称 1kubectl get pvc datadir-mongo-mongodb-sharded-shard0-data-0 -n mongo 输出结果中VOLUME 那一列就是 PV 的名字。 123kubectl get pvc datadir-mongo-mongodb-sharded-shard0-data-0 -n mongoNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEdatadir-mongo-mongodb-sharded-shard0-data-0 Bound pvc-82de37fd-b2c7-4b90-8b83-553da08114f0 100Gi RWO local-storage 16d 第三步：查看 PV 的物理路径 1kubectl get pv pvc-82de37fd-b2c7-4b90-8b83-553da08114f0 -o yaml spec 部分，查看路径信息。hostPath的path，就是物理地址了。来到这个路径，可以看到里面有.wt文件，这就是mongo存储数据的文件了。 从抽象需求（Pod&#x2F;PVC）到具体实现（PV&#x2F;物理路径）的逐层剥离： Pod 层 (mongo-shard0-data-0)： 视角： “我是数据库程序，我只知道把数据写到容器内的 &#x2F;bitnami&#x2F;mongodb&#x2F;data 目录。这个目录挂载了一个叫 datadir 的卷。” 线索： ClaimName: datadir-mongo-0 (我有这张提货券)。 PVC 层 (datadir-mongo-0)： 视角： “我是提货券，我要求 10GB 的空间。K8s 告诉我，我已经绑定到了 pvc-abcd-1234 这个资源上。” 线索： Volume: pvc-abcd-1234。 PV 层 (pvc-abcd-1234)： 视角： “我是真正的存储资源对象。我有详细的连接信息。我的类型是 HostPath。” 线索： Path: &#x2F;data&#x2F;k8s-volumes&#x2F;mongo&#x2F;shard0。 物理层 (Linux Server)： 视角： “我是硬盘上的一个文件夹。我就在 &#x2F;data&#x2F;k8s-volumes&#x2F;mongo&#x2F;shard0。” 为什么pod不能直接写死路径： 不可移植： 如果你的 Pod 迁移到了另一台服务器，或者换了一个集群，而新环境里没有 192.168.1.5 这台机器，Pod 就直接报错跑不起来了。 开发与运维分离： 开发人员（写 Pod 的人）通常不知道、也不应该关心服务器的 IP 和硬盘路径。运维人员（管 PV 的人）才需要关心。 分片架构为什么要这样设计核心理念只有四个字：**分而治之 (Divide and Conquer)**。 它的目的是为了解决单机性能瓶颈（磁盘不够大、CPU 跑满、内存不足）。为了实现无限的水平扩展（Horizontal Scaling），MongoDB 将功能拆解成了这三个独立的组件。 可以用一个“大型物流中心”的例子来完美类比这个架构： Mongos：前台接待&#x2F;调度员 (Router) 对应你的 Pod： mongo-mongodb-sharded-mongos-0 角色特点： 无状态、不存货、只动嘴。 为什么这么设计？ 它是应用程序（App）的唯一入口。你的代码只需要连接 mongos，就像你寄快递只找前台一样。 不存数据：因为它是负责计算路由逻辑的。它需要消耗 CPU 来解析你的查询命令，计算出数据在哪个分片上。 作用： 如果没有它，你的 App 就得自己去记“张三的数据在服务器 A，李四的数据在服务器 B”，这太痛苦了。Mongos 屏蔽了底层的复杂性。 Config Server：仓库账本&#x2F;目录管理员 (Metadata) 对应你的 Pod： mongo-mongodb-sharded-configsvr-0 角色特点： 存目录、数据量小、极度重要。 为什么这么设计？ 它存储的是**“元数据” (Metadata)**。也就是一张巨大的“地图”。 它记录了：“数据被切成了几块？如果在服务器 A 找不到，应该去服务器 B 找吗？哪个分片负责哪个范围的数据？” 关系： mongos 接到请求后，必须先问 Config Server：“嘿，用户要查 ID&#x3D;100 的数据，他在哪个仓库？”然后 mongos 才知道去哪里拿数据。 注意： 虽然它也存数据，但存的是配置信息，不是业务数据，所以它通常不需要很大的磁盘，但要求极高的数据一致性。 Shard (Data Node)：真正的仓库&#x2F;搬运工 (Data Storage) 对应你的 Pod： mongo-mongodb-sharded-shard0-data-0 角色特点： 存真货、干苦力、可无限增加。 为什么这么设计？ 这里存储了你真正的业务数据（比如用户表、订单表）。 分片 (Sharding) 的意思就是：假设你有 100TB 数据，不可能塞进一台机器。于是我们把数据切碎： Shard-0 存“A开头~H开头”的用户。 Shard-1 存“I开头~Z开头”的用户。 作用： 这就是为什么你要找数据必须看这个 Pod 的原因。所有的磁盘 I&#x2F;O 读写压力都在这里。 总结：一次查询的生命周期 为了串联它们，假设你的 K8s 集群里来了一个请求：“帮我查找用户 ID &#x3D; 5000 的资料”。 第一步（Mongos）： 请求到达 mongos-0。Mongos 只是个接待员，它手里没有数据。 第二步（Config）： Mongos 悄悄看了一眼缓存里的“账本”（这个账本是从 configsvr-0 同步过来的）。账本上写着：“ID 0~10000 的数据在 Shard-0 仓库里”。 第三步（Shard）： Mongos 转头把请求转发给 shard0-data-0。 第四步（返回）： shard0-data-0 在自己的硬盘里找到数据，返回给 Mongos，Mongos 再返回给用户。 为什么要拆得这么细？（设计优势） 无限扩展能力（Horizontal Scaling）： 如果数据把 shard0 塞满了怎么办？很简单，加一组 shard1 服务器。Mongos 会自动把一部分数据搬过去。你的 App 甚至感觉不到变化，不需要停机。 性能隔离： CPU 密集型任务（如路由计算、排序聚合）由 mongos 承担。 IO 密集型任务（读写磁盘）由 shard 承担。 如果查询太慢，可以单独给 mongos 加 CPU；如果磁盘不够，可以单独给 shard 加硬盘。 高可用（High Availability）： 在这个架构中，每一个组件（Shard, Config, Mongos）通常都是多副本的。 Shard 坏了一个节点？有备份节点顶上。 Mongos 坏了一个？K8s Service 会自动把流量切到另一个 Mongos 上。 这就是为什么你在 K8s 里看到这么多不同名字的 Pod，它们各司其职，共同支撑起了一个海量数据存储系统。"},{"title":"【mongoDB】聚合框架","path":"/2025/11/28/【mongoDB】聚合框架/","content":"常见操作1.常见管道阶段 分类 运算符 作用 &#x2F; 说明 常见场景 过滤 $match 按条件筛选文档，类似 find 的 query 只要上架商品、只要本月数据 投影&#x2F;加字段 $project &#x2F; $addFields &#x2F; $set 控制输出字段、重命名字段、增加计算字段 只返回必要字段、计算 finalPrice 分组统计 $group 按 _id 分组并做聚合（求和、计数、均值等） 按用户&#x2F;按天统计金额、数量 排序&#x2F;分页 $sort &#x2F; $skip &#x2F; $limit 排序、跳过 N 条、限制返回条数 列表页排序 + 分页 展开数组 $unwind 把数组里的每个元素“拆成多行” 订单里的 items 一条一条展开 关联集合 $lookup 类似左连接，把另一集合的数据查出来放到数组字段里 订单关联用户信息 多路统计 $facet 一次遍历，同时走多条子管道，返回多个统计结果 一次请求返回多种统计面板 分组计数排序 $sortByCount 对某个字段分组计数并按数量排序，相当于 $group + $sort 统计每个标签出现次数 计数 $count 统计当前管道流经文档总数，输出 { total: } 快速得到总数 一般常见使用顺序：原则：始终注意聚合管道的效率，确保限制文档数量。 1.匹配 $match | 相当于find，用来筛选符合条件的文档。 2.排序 $sort | 如果顺序很重要，一般会放在前面。 3.分页 $skip $limit | 表示从第几个开始，限制返回多少个。 4.投影 $project | 限制返回的字段。 例子： 123456789101112131415161718192021222324252627282930313233db.orders.aggregate([ // 只要本月订单 &#123; $match: &#123; createdAt: &#123; $gte: ISODate(&quot;2025-11-01T00:00:00Z&quot;), $lt: ISODate(&quot;2025-12-01T00:00:00Z&quot;) &#125; &#125; &#125;, // 按 userId 分组统计 &#123; $group: &#123; _id: &quot;$userId&quot;, orderCount: &#123; $sum: 1 &#125;, totalAmount: &#123; $sum: &quot;$amount&quot; &#125;, avgAmount: &#123; $avg: &quot;$amount&quot; &#125; &#125; &#125;, // 只要订单数 ≥ 3 的用户 &#123; $match: &#123; orderCount: &#123; $gte: 3 &#125; &#125; &#125;, // 输出格式美化 &#123; $project: &#123; _id: 0, userId: &quot;$_id&quot;, orderCount: 1, totalAmount: 1, avgAmount: 1 &#125; &#125;, &#123; $sort: &#123; totalAmount: -1 &#125; &#125;]) 2.常见聚合函数（累加器，主要在 $group 中） 类型 运算符 说明 统计类 $sum 求和；$sum: 1 时等价于计数 $avg 求平均值 $min &#x2F; $max 组内最小值 &#x2F; 最大值 $first &#x2F; $last 组内第一条 &#x2F; 最后一条文档的字段值（依赖排序） 收集类 $push 把每个值放进数组（允许重复） $addToSet 把不重复的值放进数组（自动去重） 3.常见表达式运算符（在 $project &#x2F; $addFields &#x2F; $group 等里用） 分类 运算符示例 说明 &#x2F; 用途 数学运算 $add &#x2F; $subtract &#x2F; $multiply &#x2F; $divide &#x2F; $mod 加减乘除、取余；如算含税价、差值等 字符串 $concat 拼接字符串（如 firstName + lastName） $substr &#x2F; $substrBytes &#x2F; $substrCP 截取字符串 $toUpper &#x2F; $toLower 大小写转换 日期 $year &#x2F; $month &#x2F; $dayOfMonth &#x2F; $hour 从日期中抽取年份、月份、日、小时等 $dateToString 格式化日期为字符串（如 YYYY-MM-DD） 条件判断 $cond if-else：condition ? then : else $ifNull 字段为 null&#x2F;不存在时给默认值 $switch 多分支条件判断 数组相关 $size 数组长度 $slice 取数组前 N 个元素 $in 判断某值是否在数组中"},{"title":"【算法】缓存淘汰算法LRU/LFU","path":"/2025/04/02/【算法】缓存淘汰算法LRU-LFU/","content":"无论是什么系统，在研发的过程中不可避免的会使用到缓存，而缓存一般来说我们不会永久存储，但是缓存的内容是有限的，那么我们如何在有限的内存空间中，尽可能的保留有效的缓存信息呢？ 那么我们就可以使用 LRU/LFU算法 ，来维持缓存中的信息的时效性。 LRU 详解原理 LRU （Least Recently Used：最近最少使用）算法在缓存写满的时候，会根据所有数据的访问记录，淘汰掉未来被访问几率最低的数据。也就是说该算法认为，最近被访问过的数据，在将来被访问的几率最大。 流程如下：假设我们有这么一块内存，一共有26个数据存储块。 当我们连续插入A、B、C、……、Z的时候，此时内存已经插满了 那么当我们再插入一个6，那么此时会将内存存放时间最久的数据A淘汰掉 当我们从外部读取数据C的时候，此时C就会提到头部，这时候C就是最晚淘汰的了 拆分一下的话，就是在维护一个双向链表 （当然在Java中就是用LinkedList，不过查找起来就比较麻烦，HashMap查找起来比较方便，即可以使用散列表来实现，ArrayList就要挪动太多元素了） 代码实现 定义一个存放的数据块结构 1234567type item struct &#123;\tkey string\tvalue any // the frequency of key (用来扩展LFU逻辑)\tfreq int&#125; 定义LRU算法的结构体 1234567type LRU struct &#123;\tdl *list.List // 维护的双端队列\tsize int // 当前的容量\tcapacity int // 限定的容量\tstorage map[string]*list.Element // 存储的key&#125; 获取某个key的value的函数，如果存在这个key，那么我们就把这个值移动到最前面MoveToFront，否则返回一个nil。 123456789func (c *LRU) Get(key string) any &#123;\tv, ok := c.storage[key]\tif ok &#123; c.dl.MoveToFront(v) return v.Value.(item).value\t&#125;\treturn nil&#125; 当我们需要put进去一些东西的时候。会分以下几个步骤 是否已经存在，如果已经存在则，直接返回，并且将key移动到最前面。 如果没有存在，但是已经是到极限容量了，就把最后一个Back()，淘汰掉，然后再塞入。 塞入的话，是塞入到最前面PushFront 123456789101112131415161718192021222324func (c *LRU) Put(key string, value any) &#123;\te, ok := c.storage[key]\tif ok &#123; n := e.Value.(item) n.value = value e.Value = n c.dl.MoveToFront(e) return\t&#125;\tif c.size &gt;= c.capacity &#123; e = c.dl.Back() dk := e.Value.(item).key c.dl.Remove(e) delete(c.storage, dk) c.size--\t&#125;\tn := item&#123;key: key, value: value&#125;\tc.dl.PushFront(n)\tne := c.dl.Front()\tc.storage[key] = ne\tc.size++&#125; 以上就是LRU算法的所有内容了，那我们看一下LFU算法。 LFU原理 LFU全称是最不经常使用算法（Least Frequently Used），LFU算法的基本思想和所有的缓存算法一样，一定时期内被访问次数最少的页，在将来被访问到的几率也是最小的。 相比于LRU（Least Recently Use）算法，LFU更加注重于使用的频率 。**LRU是其实可以看作是频率为1的LFU的。** 和LRU不同的是，LFU是根据频率排序的，当我们插入的时候，一般会把新插入的放到链表的尾部，因为新插入的一定是没有出现过的，所以频率都会是1 ， 所以会放在最后。 所以LFU的插入顺序如下： 如果A没有出现过，那么就会放在双向链表的最后，依次类推，就会是Z、Y。。C、B、A的顺序放到频率为1的链表中。 当我们新插入 A，B，C 那么A，B，C就会到频率为2的链表中 如果再次插入A，B那么A，B会在频率为3中。C依旧在2中 如果此时已经满了 ，新插入一个的话，我们会把最后一个D移除，并插入 6 代码定义一个LFU的结构体： 12345678910111213// LFU the Least Frequently Used (LFU) page-replacement algorithmtype LFU struct &#123;\tlen int // length\tcap int // capacity\tminFreq int // The element that operates least frequently in LFU\t// key: key of element, value: value of element\titemMap map[string]*list.Element\t// key: frequency of possible occurrences of all elements in the itemMap\t// value: elements with the same frequency\tfreqMap map[int]*list.List // 维护一个频率和list的集合&#125; 我们使用LFU算法的话，我们插入的元素就需要带上频率了 12345678// initItem to init item for LFUfunc initItem(k string, v any, f int) item &#123;\treturn item&#123; key: k, value: v, freq: f,\t&#125;&#125; 如果我们获取某个元素，那么这个元素如果存在，就会对这个元素的频率进行加1 12345678910111213// Get the key in cache by LFUfunc (c *LFU) Get(key string) any &#123;\t// if existed, will return value\tif e, ok := c.itemMap[key]; ok &#123; // the frequency of e +1 and change freqMap c.increaseFreq(e) obj := e.Value.(item) return obj.value\t&#125;\t// if not existed, return nil\treturn nil&#125; 增加频率 1234567891011121314// increaseFreq increase the frequency if elementfunc (c *LFU) increaseFreq(e *list.Element) &#123;\tobj := e.Value.(item)\t// remove from low frequency first\toldLost := c.freqMap[obj.freq]\toldLost.Remove(e)\t// change the value of minFreq\tif c.minFreq == obj.freq &amp;&amp; oldLost.Len() == 0 &#123; // if it is the last node of the minimum frequency that is removed c.minFreq++\t&#125;\t// add to high frequency list\tc.insertMap(obj)&#125; 插入key到LFU缓存中 如果存在就对频率加1 如果不存在就准备插入 如果溢出了，就把最少频率的删除 如果没有溢出，那么就放到最后 123456789101112131415161718192021222324// Put the key in LFU cachefunc (c *LFU) Put(key string, value any) &#123;\tif e, ok := c.itemMap[key]; ok &#123; // if key existed, update the value obj := e.Value.(item) obj.value = value c.increaseFreq(e)\t&#125; else &#123; // if key not existed obj := initItem(key, value, 1) // if the length of item gets to the top line // remove the least frequently operated element if c.len == c.cap &#123; c.eliminate() c.len-- &#125; // insert in freqMap and itemMap c.insertMap(obj) // change minFreq to 1 because insert the newest one c.minFreq = 1 // length++ c.len++\t&#125;&#125; 插入一个新的 123456789101112// insertMap insert item in mapfunc (c *LFU) insertMap(obj item) &#123;\t// add in freqMap\tl, ok := c.freqMap[obj.freq]\tif !ok &#123; l = list.New() c.freqMap[obj.freq] = l\t&#125;\te := l.PushFront(obj)\t// update or add the value of itemMap key to e\tc.itemMap[obj.key] = e&#125; 找到最少的链表，并且删除 123456789// eliminate clear the least frequently operated elementfunc (c *LFU) eliminate() &#123;\tl := c.freqMap[c.minFreq]\te := l.Back()\tobj := e.Value.(item)\tl.Remove(e)\tdelete(c.itemMap, obj.key)&#125; 以上就是所有LFU的算法实现了。 —在研究如何识别热key时发现，阿里是在代理层，借助LFU写的，所以说这玩意儿还是有用啊，我学学学！ 参考资料： 图解缓存淘汰算法 LRU、LFU ｜ 最近最少使用、最不经常使用算法 ｜ go语言实现 不该这么嚣张的，B站面试官水平真高，手写LRU算法失算了"},{"title":"【系统设计】如何定位Redis热key","path":"/2025/04/02/【系统设计】如何定位Redis热key/","content":"热key指一段时间内被频繁访问或操作的键。通常出现在商品限时抢购、瞬时新闻热点等业务场景，可能会对系统的稳定性和可用性造成影响，比如对应节点的网卡带宽被打满，出现丢包重传，请求波动耗时大幅上升，甚至影响到业务的正常使用，引发用户的不满。因此，不可能等到热Key出现已经拖垮了服务再去处理，那个时候业务一定已经受到影响，因此需要提前尽可能在设计和开发时避免引入全局热key，另外，真实的生成环境还是可能存在边界case、非预期的流量等，因此快速定位热key仍然需要研究。 需要做到高并发和高性能，对于高频变化的动态数据通常采用多级缓存，搭配缓存预热、缓存失效时长等手段控制。 按照实现的原理，我们可以尝试利用内置的命令或工具，或者外部流量工具，甚至代码层面开统计key的访问频率，进而对热key做进一步操作。 一、探测思路从Redis请求路径的节点入手。 1. 客户端收集上报改动 Redis SDK，记录每个请求，定时把收集到的数据上报，然后由一个统一的服务进行聚合计算。 优点：方案直观简单 缺点：没法适应多语言架构，一方面多语言 SDK 对齐是个问题，另外一方面后期 SDK 的维护升级会面临比较大的困难，成本很高 2. 代理层收集上报如果所有的 Redis 请求都经过代理的话，可以考虑改动 Proxy 代码进行收集，思路与客户端基本类似。 优点：对使用方完全透明，能够解决客户端 SDK 的语言异构和版本升级问题 缺点：开发成本会比客户端高些 3. Redis 数据定时扫描利用Redis自带的工具，优点：无需进行二次开发，能够直接利用现成的工具。 （1）--hotkeys 参数 Redis在4.0版本后提供了hotkeys功能，可以通过redis-cli --hotkeys命令获取当前keyspace的热点key，实现上是通过 scan + object freq 完成的。 缺点： 由于需要扫描整个 keyspace，实时性上比较差; 扫描时间与 key 的数量正相关，如果 key 的数量比较多，耗时可能会非常长。 （2） monitor命令 通过 redis-cli monitor实时抓取出 Redis 服务器接收到的命令，同时结合一些现成的分析工具，比如 redis-faina，统计出热 Key。 缺点：在高并发的条件下，有内存暴增的隐患，还会降低 Redis 的性能。 （3）慢查询日志 使用redis-cli slowlog命令查看慢查询日志，记录执行时间超过阈值的命令。间接发现热Key，侧重慢查询，非高频访问。 4. Redis 节点抓包解析在可能存在热 key 的节点上(流量倾斜判断)，通过 tcpdump 抓取一段时间内的流量并上报，然后由一个外部的程序进行解析、聚合和计算。 优点：该方案无需侵入现有的 SDK 或者 Proxy 中间件，开发维护成本可控 缺点：热 key 节点的网络流量和系统负载已经比较高了，抓包可能会情况进一步恶化 二、热key的治理三、生产案例阿里第二层，代理层上报 京东 Jdhotkey解决的是广义的热key问题，不属于探测思路章节中四种中的任何一种，不修改Redis SDK、不依赖Proxy、不扫描Redis数据、也不抓包。它通过独立的ETCD+Worker集群实现热key探测，与Redis无耦合。 相关补充： DAU（Daily Active Users，日活跃用户数），指一天内（24小时内）使用产品或服务的独立用户数量，是衡量产品活跃度和用户粘性的重要指标之一。具体由产品的体量决定，例如20w的DAU，对于淘宝就很小，对于小众论坛就很大。 补充：在Windows如何启动redis？ 进入安装目录并cmd 运行命令redis-server.exe redis.windows.conf。如果报错，依次执行第一条指令：redis-cli.exe，第二条指令：shutdown，第三条指令：exit 参考资料： Redis 热 Key 发现以及解决办法 如何快速定位 Redis 热 key（上）-阿里云开发者社区 工具推荐： Redis-faina:facebookarchive&#x2F;redis-faina: A query analyzer that parses Redis’ MONITOR command for counter&#x2F;timing stats about query patterns (github.com) 京东热key探测框架：京东毫秒级热key探测框架设计与实践，已实战于618大促"},{"title":"【系统设计】秒杀系统实现方案与技术","path":"/2025/03/28/【系统设计】秒杀系统实现方案与技术/","content":"秒杀系统作为互联网“高并发、高性能、高可用”系统的代表，从系统设计、数据处理到运维保障等方面都有很多可以考察和深挖的点，本文将尝试分析涉及的关键问题，并总结相关的最佳实践。 秒杀系统的核心挑战在于平衡性能、一致性与安全性。 秒杀系统中常见的问题包括：超卖问题、高并发性能瓶颈、数据一致性问题、分布式锁失效、事务管理失效、安全与放作弊问题、系统监控与运维等。 通过分层架构（如流量削峰、异步化）、原子操作（如Lua脚本）、分布式协调（如Redis锁）及全周期管理（监控+应急预案）综合解决。设计时应优先保障核心链路（如库存扣减），非核心功能（如积分赠送）允许降级或最终一致性。 从“高并发、高性能、高可用”来看高并发 限流 流量削峰漏斗：业务校验分层过滤（如，账号安全、购买资格-&gt;系统基本信息-&gt;商品信息-&gt;秒杀时间-&gt;数据库写操作） 接口限流：借助现有组件，如Sentinel 问题、验证码：避免请求集中、解决脚本作弊等问题（如，对正确性校验、对提交时间校验） 提前预约：提前筛选黄牛 高性能也关于高并发 热点数据隔离：分为静态和动态 静态数据基本不变，例如商品信息等：利用CDN内容分发服务器 动态数据高频变化，例如库存等： 多级缓存 缓存预热 缓存失效时长控制 本地缓存LocalCache 少量极热数据可以放在JVM 涉及另一个问题：识别热点key 中间件层面：如京东零售的hotkey 高可用 集群化 流量削峰：借助消息队列 降级：优先保证核心业务（应对系统自身的故障） 熔断：中断对该服务的调用（应对系统依赖外部系统或第三方的故障） 从数据一致性来看扣减库存方案首先常见的方案包括下单扣减库存（常用）和付款扣减库存，另外超时不付款则释放库存。 一个很常见的是超卖问题。其解决方案： 提前把商品信息放到缓存（考虑分布式缓存） 通过lua脚本操作Redis，执行原子性操作 数据库唯一键 余额扣减方案 并发高：悲观锁 数据库的排他锁 并发不高：乐观锁 版本号机制 （注意ABA问题） 系统架构设计以阿里电影节为例 架构设计上，介入统一网关进行安全保障和限流，库存和订单的数据隔离，加入多级缓存： 业务设计上，对外业务和后台管理可以分开。内网的业务服务、基础服务和中间件分开： 其他针对恶意操作 库存失效时间 限制用户购买数量 黄牛防控系统 性能测试 常用工具 Jmeter LoadRunner Galtling ab 其他： 精准监控 数据大盘 接口幂等 状态机 分布式锁 —作为项目挖掘机的记录……待补充完善……"},{"title":"【数据库】如何保障数据库和缓存一致性","path":"/2025/03/27/【数据库】如何保障数据库和缓存一致性/","content":"数据库和缓存的一致性问题，在面试以及实践中都是非常重要的知识点，而一般面试者只能说出最佳的实践是什么（即延迟双删或者先更新数据库再删除缓存key），但是不能通过线程之间的读写关系举例说明为什么要这样实践，本文通过穷尽更新缓存的四种方式进行分析，得出了这个结论。最后，本文还介绍了利用消息中间件MQ应对其他更复杂的情形。 [建议先看思维导图和How的总结] Why缓存？ 缓存合理使用确提升了系统的吞吐量和稳定性，然而这是有代价的。这个代价便是缓存和数据库的一致性带来了挑战，本文将针对最常见的 cache-aside 策略下如何维护缓存一致性彻底讲透。 在真实的业务场景中，我们的业务的数据——例如订单、会员、支付等——都是持久化到数据库中的，因为数据库能有很好的事务保证、持久化保证。但是，正因为数据库要能够满足这么多优秀的功能特性，使得数据库在设计上通常难以兼顾到性能，因此往往不能满足大型流量下的性能要求，像是 MySQL 数据库只能承担“千”这个级别的 QPS，否则很可能会不稳定，进而导致整个系统的故障。 但是客观上，我们的业务规模很可能要求着更高的 QPS，有些业务的规模本身就非常大，也有些业务会遇到一些流量高峰，比如电商会遇到大促的情况。 而这时候大部分的流量实际上都是读请求，而且大部分数据也是没有那么多变化的，如热门商品信息、微博的内容等常见数据就是如此。此时，缓存就是我们应对此类场景的利器。 所谓缓存，实际上就是用空间换时间，准确地说是用更高速的空间来换时间，从而整体上提升读的性能。 何为更高速的空间呢？ 更快的存储介质。通常情况下，如果说数据库的速度慢，就得用更快的存储组件去替代它，目前最常见的就是 Redis（内存存储）。Redis 单实例的读 QPS 可以高达 10w&#x2F;s，90% 的场景下只需要正确使用 Redis 就能应对。 就近使用本地内存。就像 CPU 也有高速缓存一样，缓存也可以分为一级缓存、二级缓存。即便 Redis 本身性能已经足够高了，但访问一次 Redis 毕竟也需要一次网络 IO，而使用本地内存无疑有更快的速度。不过单机的内存是十分有限的，所以这种一级缓存只能存储非常少量的数据，通常是最热点的那些 key 对应的数据。这就相当于额外消耗宝贵的服务内存去换取高速的读取性能。 Challenges？引入缓存后的一致性挑战 用空间换时间，意味着数据同时存在于多个空间。最常见的场景就是数据同时存在于 Redis 与 MySQL 上（为了问题的普适性，后面举例中若没有特别说明，缓存均指 Redis 缓存）。 实际上，最权威最全的数据还是在 MySQL 里的。而万一 Redis 数据没有得到及时的更新（例如数据库更新了没更新到 Redis），就出现了数据不一致。 大部分情况下，只要使用了缓存，就必然会有不一致的情况出现，只是说这个不一致的时间窗口是否能做到足够的小。有些不合理的设计可能会导致数据持续不一致，这是我们需要改善设计去避免的。 这里的一致性实际上对于本地缓存也是同理的，例如数据库更新后没有及时更新本地缓存，也是有一致性问题的，下文统一以 Redis 缓存作为引子讲述，实际上处理本地缓存原理基本一致。 缓存不一致性无法客观地完全消灭 为什么我们几乎没办法做到缓存和数据库之间的强一致呢？ 理想情况下，我们需要在数据库更新完后把对应的最新数据同步到缓存中，以便在读请求的时候能读到新的数据而不是旧的数据（脏数据）。但是很可惜，由于数据库和 Redis 之间是没有事务保证的，所以我们无法确保写入数据库成功后，写入 Redis 也是一定成功的；即便 Redis 写入能成功，在数据库写入成功后到 Redis 写入成功前的这段时间里，Redis 数据也肯定是和 MySQL 不一致的。如下两图所示： 无法事务保持一致 所以说这个时间窗口是没办法完全消灭的，除非我们付出极大的代价，使用分布式事务等各种手段去维持强一致，但是这样会使得系统的整体性能大幅度下降，甚至比不用缓存还慢，这样不就与我们使用缓存的目标背道而驰了吗？ 不过虽然无法做到强一致，但是我们能做到的是缓存与数据库达到最终一致，而且不一致的时间窗口我们能做到尽可能短，按照经验来说，如果能将时间优化到 1ms 之内，这个一致性问题带来的影响我们就可以忽略不计。 最终一致性如何保证？–&gt;缓存设置过期时间 第一个方法便是我们上面提到的，当我们无法确定 MySQL 更新完成后，缓存的更新&#x2F;删除一定能成功，例如 Redis 挂了导致写入失败了，或者当时网络出现故障，更常见的是服务当时刚好发生重启了，没有执行这一步的代码。 这些时候 MySQL 的数据就无法刷到 Redis 了。为了避免这种不一致性永久存在，使用缓存的时候，我们必须要给缓存设置一个过期时间，例如 1 分钟，这样即使出现了更新 Redis 失败的极端场景，不一致的时间窗口最多也只是 1 分钟。 这是我们最终一致性的兜底方案，万一出现任何情况的不一致问题，最后都能通过缓存失效后重新查询数据库，然后回写到缓存，来做到缓存与数据库的最终一致。 How更新缓存?引言 通常情况下，我们在处理查询请求的时候，使用缓存的逻辑如下： 1234567data = queryDataRedis(key);if (data ==null) &#123; data = queryDataMySQL(key); //缓存查询不到，从MySQL做查询 if (data!=null) &#123; updateRedis(key, data);//查询完数据后更新MySQL最新数据到Redis &#125;&#125; 也就是说优先查询缓存，查询不到才查询数据库。如果这时候数据库查到数据了，就将缓存的数据进行更新。这是我们常说的 cache aside 的策略，也是最常用的策略。 这样的逻辑是正确的，而一致性的问题一般不来源于此，而是出现在处理写请求的时候。所以我们简化成最简单的写请求的逻辑，此时你可能会面临多个选择，究竟是直接更新缓存，还是失效缓存？而无论是更新缓存还是失效缓存，都可以选择在更新数据库之前，还是之后操作。 这样就演变出 4 个策略：更新数据库后更新缓存、更新数据库前更新缓存、更新数据库后删除缓存、更新数据库前删除缓存。下面我们来分别讲述。 1. 更新数据库后更新缓存的不一致问题一种常见的操作是，设置一个过期时间，让写请求以数据库为准，过期后，读请求同步数据库中的最新数据给缓存。那么在加入了过期时间后，是否就不会有问题了呢？并不是这样。 大家设想一下这样的场景。 假如这里有一个计数器，把数据库自减 1，原始数据库数据是 100，同时有两个写请求申请计数减一，假设线程 A 先减数据库成功，线程 B 后减数据库成功。那么这时候数据库的值是 98，缓存里正确的值应该也要是 98。 但是特殊场景下，你可能会遇到这样的情况： 线程 A 和线程 B 同时更新这个数据。 更新数据库的顺序是先 A 后 B。 更新缓存时顺序是先 B 后 A。 如果我们的代码逻辑还是更新数据库后立刻更新缓存的数据，那么—— 12updateMySQL();updateRedis(key, data); 就可能出现：数据库的值是 100-&gt;99-&gt;98，但是缓存的数据却是 100-&gt;98-&gt;99，也就是数据库与缓存的不一致。而且这个不一致只能等到下一次数据库更新或者缓存失效才可能修复。 时间线程A（写请求）线程B（写请求）问题T1更新数据库为99T2更新数据库为98T3更新缓存数据为98T4更新缓存数据为99此时缓存的值被显式更新为99，但是实际上数据库的值已经是98，数据不一致 当然，如果更新 Redis 本身是失败的话，两边的值固然也是不一致的，这个前文也阐述过，几乎无法根除。 2. 更新数据库前更新缓存的不一致问题那你可能会想，这是否表示，我应该先让缓存更新，之后再去更新数据库呢？类似这样： 12updateRedis(key, data);//先更新缓存updateMySQL();//再更新数据库 这样操作产生的问题更是显而易见的，因为我们无法保证数据库的更新成功，万一数据库更新失败了，你缓存的数据就不只是脏数据，而是错误数据了。 你可能会想，是否我在更新数据库失败的时候做 Redis 回滚的操作能够解决呢？这其实也是不靠谱的，因为我们也不能保证这个回滚的操作 100% 被成功执行。 同时，在写写并发的场景下，同样有类似的一致性问题，请看以下情况： 线程 A 和线程 B 同时更新同这个数据。 更新缓存的顺序是先 A 后 B。 更新数据库的顺序是先 B 后 A。 举个例子。线程 A 希望把计数器置为 0，线程 B 希望置为 1。而按照以上场景，缓存确实被设置为 1，但数据库却被设置为 0。 所以通常情况下，更新缓存再更新数据库是我们应该避免使用的一种手段。 3. 更新数据库前删除缓存的问题那如果采取删除缓存的策略呢？也就是说我们在更新数据库的时候失效对应的缓存，让缓存在下次触发读请求时进行更新，是否会更好呢？同样地，针对在更新数据库前和数据库后这两个删除时机，我们来比较下其差异。 最直观的做法，我们可能会先让缓存失效，然后去更新数据库，代码逻辑如下： 12deleteRedis(key);//先删除缓存让缓存失效updateMySQL();//再更新数据库 这样的逻辑看似没有问题，毕竟删除缓存后即便数据库更新失败了，也只是缓存上没有数据而已。然后并发两个写请求过来，无论怎么样的执行顺序，缓存最后的值也都是会被删除的，也就是说在并发写写的请求下这样的处理是没问题的。 然而，这种处理在读写并发的场景下却存在着隐患。 还是刚刚更新计数的例子。例如现在缓存的数据是 100，数据库也是 100，这时候需要对此计数减 1，减成功后，数据库应该是 99。如果这之后触发读请求，缓存如果有效的话，里面应该也要被更新为 99 才是正确的。 那么思考下这样的请求情况： 线程 A 更新这个数据的同时，线程 B 读取这个数据。 线程 A 成功删除了缓存里的老数据，这时候线程 B 查询数据发现缓存失效。 线程 A 更新数据库成功。 时间线程A（写请求）线程B（读请求）问题T1删除缓存值T21.读取缓存数据，缓存缺失，从数据库读取数据100T3更新数据库中的数据X的值为99T4将数据100的值写入缓存此时缓存的值被显式更新为100，但是实际上数据库的值已经是99了 可以看到，在读写并发的场景下，一样会有不一致的问题。 针对这种场景，有个做法是所谓的“延迟双删策略”，就是说，既然可能因为读请求把一个旧的值又写回去，那么我在写请求处理完之后，等到差不多的时间延迟再重新删除这个缓存值。 时间线程A（写请求）线程C（新的读请求）线程D（新的读请求）问题T5sleep(N)缓存存在，读取到缓存旧值100其他线程可能在双删成功前读到脏数据T6删除缓存值T7缓存缺失，从数据库读取数据的最新值（99） 这种解决思路的关键在于对 N 的时间的判断，如果 N 时间太短，线程 A 第二次删除缓存的时间依旧早于线程 B 把脏数据写回缓存的时间，那么相当于做了无用功。而 N 如果设置得太长，那么在触发双删之前，新请求看到的都是脏数据。 4. 更新数据库后删除缓存那如果我们把更新数据库放在删除缓存之前呢，问题是否解决？我们继续从读写并发的场景看下去，有没有类似的问题。 时间线程A（写请求）线程B（读请求）线程C（读请求）潜在问题T1更新主库 X = 99（原值 X = 100）T2读取数据，查询到缓存还有数据，返回100线程C实际上读取到了和数据库不一致的数据T3删除缓存T4查询缓存，缓存缺失，查询数据库得到当前值99T5将99写入缓存 可以看到，大体上，采取先更新数据库再删除缓存的策略是没有问题的，仅在更新数据库成功到缓存删除之间的时间差内——[T2,T3)的窗口 ，可能会被别的线程读取到老值。 而在开篇的时候我们说过，缓存不一致性的问题无法在客观上完全消灭，因为我们无法保证数据库和缓存的操作是一个事务里的，而我们能做到的只是尽量缩短不一致的时间窗口。 在更新数据库后删除缓存这个场景下，不一致窗口仅仅是 T2 到 T3 的时间，内网状态下通常不过 1ms，在大部分业务场景下我们都可以忽略不计。因为大部分情况下一个用户的请求很难能再 1ms 内快速发起第二次。 但是真实场景下，还是会有一个情况存在不一致的可能性，这个场景是读线程发现缓存不存在，于是读写并发时，读线程回写进去老值。并发情况如下： 时间线程A（写请求）线程B（读请求--缓存不存在场景）潜在问题T1查询缓存，缓存缺失，查询数据库得到当前值100T2更新主库 X = 99（原值 X = 100）T3删除缓存T4将100写入缓存此时缓存的值被显式更新为100，但是实际上数据库的值已经是99了 总的来说，这个不一致场景出现条件非常严格，因为并发量很大时，缓存不太可能不存在；如果并发很大，而缓存真的不存在，那么很可能是这时的写场景很多，因为写场景会删除缓存。 所以待会我们会提到，写场景很多时候实际上并不适合采取删除策略。 总结 【总结】红字为相应的解决方案，但是这些方案或多或少都存在一些问题： 分布式锁：操作重 用MQ确认：复杂 延迟双删：关键在于sleep(N)的N 太短：早于新的读请求，于是新的读请求请求了数据库又往缓存写入了脏数据，无用功 太长：新的读请求都得到了脏数据 【总结】最佳实践：更新数据库后删除缓存值 读多写少–&gt;更新数据库后删除缓存 读写相当&#x2F;写多读少–&gt;更新数据库后更新缓存 【原总结，看完上面的还没理解可以往下看】终上所述，我们对比了四个更新缓存的手段，做一个总结对比，其中应对方案也提供参考，具体不做展开，如下表： 策略并发场景潜在问题应对方案更新数据库+更新缓存写+读线程A未更新完缓存之前，线程B的读请求会短暂读到旧值可以忽略写+写更新数据库的顺序是先A后B，但更新缓存时顺序是先B后A，数据库和缓存数据不一致分布式锁（操作重）更新缓存+更新数据库无并发线程A还未更新完缓存但是更新数据库可能失败利用MQ确认数据库更新成功（较复杂）写+写更新缓存的顺序是先A后B，但更新数据库时顺序是先B后A分布式锁（操作很重）删除缓存值+更新数据库写+读写请求的线程A删除了缓存在更新数据库之前，这时候读请求线程B到来，因为缓存缺失，则把当前数据读取出来放到缓存，而后线程A更新成功了数据库延迟双删（但是延迟的时间不好估计，且延迟的过程中依旧有不一致的时间窗口）更新数据库+删除缓存值写+读（缓存命中）线程A完成数据库更新成功后，尚未删除缓存，线程B有并发读请求会读到旧的脏数据可以忽略写+读（缓存不命中）读请求不命中缓存，写请求处理完之后读请求才回写缓存，此时缓存不一致分布式锁（操作重） 从一致性的角度来看，采取更新数据库后删除缓存值，是更为适合的策略。因为出现不一致的场景的条件更为苛刻，概率相比其他方案更低。 那么是否更新缓存这个策略就一无是处呢？不是的！ 删除缓存值意味着对应的 Key 会失效，那么这时候读请求都会打到数据库。如果这个数据的写操作非常频繁，就会导致缓存的作用变得非常小。而如果这时候某些 Key 还是非常大的热 Key，就可能因为扛不住数据量而导致系统不可用。 如下图所示： 删除策略频繁的缓存失效导致读请求无法利用缓存 所以做个简单总结，足以适应绝大部分的互联网开发场景的决策： 针对大部分读多写少场景，建议选择更新数据库后删除缓存的策略。 针对读写相当或者写多读少的场景，建议选择更新数据库后更新缓存的策略。 Addition:消息中间件的运用 如何减少缓存删除&#x2F;更新的失败？万一删除缓存这一步因为服务重启没有执行，或者 Redis 临时不可用导致删除缓存失败了，就会有一个较长的时间（缓存的剩余过期时间）是数据不一致的。 那我们有没有什么手段来减少这种不一致的情况出现呢？这时候借助一个可靠的消息中间件就是一个不错的选择。 因为消息中间件有 ATLEAST-ONCE 的机制，如下图所示。 我们把删除 Redis 的请求以消费 MQ 消息的手段去失效对应的 Key 值，如果 Redis 真的存在异常导致无法删除成功，我们依旧可以依靠 MQ 的重试机制来让最终 Redis 对应的 Key 失效。 而你们或许会问，极端场景下，是否存在更新数据库后 MQ 消息没发送成功，或者没机会发送出去机器就重启的情况？ 这个场景的确比较麻烦，如果 MQ 使用的是 RocketMQ，我们可以借助 RocketMQ 的事务消息，来让删除缓存的消息最终一定发送出去。而如果你没有使用 RocketMQ，或者你使用的消息中间件并没有事务消息的特性，则可以采取消息表的方式让更新数据库和发送消息一起成功。事实上这个话题比较大了，我们不在这里展开。 如何处理复杂的多缓存场景？有些时候，真实的缓存场景并不是数据库中的一个记录对应一个 Key 这么简单，有可能一个数据库记录的更新会牵扯到多个 Key 的更新。还有另外一个场景是，更新不同的数据库的记录时可能需要更新同一个 Key 值，这常见于一些 App 首页数据的缓存。 我们以一个数据库记录对应多个 Key 的场景来举例。 假如系统设计上我们缓存了一个粉丝的主页信息、主播打赏榜 TOP10 的粉丝、单日 TOP 100 的粉丝等多个信息。如果这个粉丝注销了，或者这个粉丝触发了打赏的行为，上面多个 Key 可能都需要更新。只是一个打赏的记录，你可能就要做： 1234updateMySQL();//更新数据库一条记录deleteRedisKey1();//失效主页信息的缓存updateRedisKey2();//更新打赏榜TOP10deleteRedisKey3();//更新单日打赏榜TOP100 这就涉及多个 Redis 的操作，每一步都可能失败，影响到后面的更新。甚至从系统设计上，更新数据库可能是单独的一个服务，而这几个不同的 Key 的缓存维护却在不同的 3 个微服务中，这就大大增加了系统的复杂度和提高了缓存操作失败的可能性。最可怕的是，操作更新记录的地方很大概率不只在一个业务逻辑中，而是散发在系统各个零散的位置。 针对这个场景，解决方案和上文提到的保证最终一致性的操作一样，就是把更新缓存的操作以 MQ 消息的方式发送出去，由不同的系统或者专门的一个系统进行订阅，而做聚合的操作。如下图： 不同业务系统订阅 MQ 消息单独维护各自的缓存 Key 通过订阅 MySQL binlog 的方式处理缓存上面讲到的 MQ 处理方式需要业务代码里面显式地发送 MQ 消息。还有一种优雅的方式便是订阅 MySQL 的 binlog，监听数据的真实变化情况以处理相关的缓存。 例如刚刚提到的例子中，如果粉丝又触发打赏了，这时候我们利用 binlog 表监听是能及时发现的，发现后就能集中处理了，而且无论是在什么系统什么位置去更新数据，都能做到集中处理。 目前业界类似的产品有 Canal，具体的操作图如下： 利用 Canel 订阅数据库 binlog 变更从而发出 MQ 消息，让一个专门消费者服务维护所有相关 Key 的缓存操作 到这里，针对大型系统缓存设计如何保证最终一致性，我们已经从策略、场景、操作方案等角度进行了细致的讲述，希望能对你起到帮助。 参考资料：一文讲透数据库缓存一致性问题 (qq.com) 扩展学习： 为什么Redis快？ 消息中间件的ATLEAST-ONCE是什么机制？ 如何更新数据库和发送MQ一起成功，事务消息是什么？消息表又是什么？ 数据库有哪些log？分别是什么作用？"},{"title":"【Kubernetes】如何搭建Kubenetes集群","path":"/2025/03/24/【Kubernetes】如何搭建Kubenetes集群/","content":"本文将使用kubeadm模式快速部署一主两从集群。 虚拟机准备首先本地需要准备：CentOS7.x-86_x64镜像，硬件至少2GB。 然后打开VMware WorkStation新建三个虚拟机（新建虚拟机教程，可以选择基础设施服务器），分别命名为master、node1、node2。 接下来确保虚拟机能够访问外网（注意宿主机不要连校园网），采用NAT模式，操作如下： 检查宿主机的适配器VMnet8的ip网段：cmd中执行ipconfig，VMnet8的ip要和外网处于同一网段 如果不在同一个网段，则手动配置VMnet8的ip和掩码 检查虚拟机：虚拟网络编辑器的NAT设置是否网段一致，手动配置 修改/etc/sysconfig/network-scripts/ifcfg-ens33文件，配置虚拟机网断、掩码、网关、DNS 使之生效：systemctl restart network 重启网络服务 （如果failed看解决 Linux 网络 “Job for network.service failed because the control process exite”） ping网关 192.168.43.2可以，ping百度 www.baidu.com可以，完成！ 系统准备"},{"title":"【Go基础】分布式事务","path":"/2025/03/23/【Go基础】分布式事务/","content":"从几个缩写讲起首先，提到事务，一般指的是数据库的事务，指逻辑上的一组操作，要么都执行，要么都不执行。 ACID，指的是数据库在写入或者更新资料时，为了保证交易正确可靠，要具备的4个特性： 缩写 英文单词 中文解释 说明 A atomicity 原子性 最小执行单位，all or nothing C consistency 一致性 执行前后一致 I isolation 隔离性 并发时，事务间不干扰 D durability 持久性 持久改变 这里要特别注意，C一致性是最终的目的，其余三个是实现C的手段。在单机上实现ACID可以通过锁、时间序列等机制。 接下来是分布式事务，与微服务密切相关，因为不同的微服务一般会使用自己的数据库，这个时候要满足ACID就比较困难了，如何保证系统中多个相关联的数据库中的数据一致？ 此时，需要选择折中的方案，为此，引进了CAP理论： 缩写 英文单词 中文解释 说明 C consistency 一致性 所有节点访问同份最新数据副本，要么返回最新数据要么失败 A availability 可用性 非故障节点在合理时间返回合理响应，不保证数据一致 P partition tolerance 分区容忍性 出现网络分区时仍对外提供服务 分布式系统必须保障能够对外提供服务，即分区容错性是必须的。不可能三角指的是在读写操作时，假设出现了网络分区，只能满足两个，即CP或者AP。这里要特别注意，如果没有出现网络分区，A和C是可以同时满足的。当数据不一致会影响业务时，选择CP，当业务需要高可用时，选择AP。常用的注册中心中，Zookeeper保证了CP，Eureka保证了AP，Nacos二者都支持。 在C和A的权衡实践中，诞生了BASE理论： 缩写 英文单词 中文解释 说明 B basically available 基本可用性 允许损失部分可用性（响应时间延长，损失部分非核心功能等） A availability 可用性 S soft-state 软状态 允许数据不一致，不影响整体可用性 E eventually consistent 最终一致性 一致的三个级别 这里需要理清一致性的3个级别： 强一致性：在银行等场景需要保证； 弱一致性：什么时候达到一致的状态完全没有保证（所以基本不用）； 最终一致性：系统保证在一定时间内达到一致，业界比较推崇，那么如何保证最终一致性： 读时修复 写时修复（性能好） 定期修复（常用） 分布式事务的解决方案在分布式系统中，如何保障各个节点之间的ACID特性？主要解决方案可分为两大类： 1. 强一致性方案 二阶段提交协议（2PC） 三阶段提交协议（3PC） 2. 最终一致性方案 补偿事务（TCC） MQ事务 Saga事务 本地消息表 其中： 2PC、3PC 属于业务代码无侵入方案，基于 XA 规范衍生而来。 TCC、Saga 属于业务入侵方案，需要开发者手动实现补偿逻辑。 MQ 事务依赖于消息队列，本地消息表不支持回滚。 强一致性方案（2PC &amp; 3PC）XA规范根据XA规范设计，首先介绍XA规范涉及的角色： AP（Application Program）：应用程序 RM（Resource Manager）：资源管理器（通常指数据库，也有文件系统、MQ系统），提供操作数据的接口等，保证数据一致和完整 TM（Transaction Manager）：事务管理器，是一个协调者的角色，协调跨库事务关联的所有RM的行为 2PC（两阶段提交） 准备阶段（Prepare） TM 记录事务开始日志，询问所有 RM 是否可以执行提交准备操作。 RM 尝试执行本地事务的预备操作：锁定资源，执行事务但不提交。[if 失败]则告知TM，并回滚自己的操作，不参与本次事务。 TM 收集RM的响应，记录事务准备完成日志。 提交阶段（Commit） 若所有 RM 均准备成功，TM 通知 RM 提交事务。 若有失败，则 TM 让所有 RM 回滚事务。 问题： 阻塞问题：等待提交时，资源被锁定。 单点故障：如果 TM 宕机，可能导致事务卡住。 3PC（三阶段提交）对 2PC 进行了改进，增加了超时机制。 CanCommit（准备阶段） TM 询问 RM 是否可提交事务。 RM 返回 Yes &#x2F; No &#x2F; 超时。 PreCommit（预提交阶段） 若所有 RM 均返回 Yes，TM 发送预提交请求。 RM 预执行事务，等待最终确认。 若有 RM 失败或超时，则 TM 发送中断请求。 DoCommit（提交阶段） 若所有 RM 均完成预提交，TM 发送最终提交请求。 进入该阶段后，基本不会失败。 改进点： 增加超时机制，避免事务永久阻塞。 通过 CanCommit 阶段减少资源长时间锁定。但是解决并不完美，性能差、数据仍然不一致，应用不广泛，一般会通过复制状态机解决2PC的阻塞问题。 最终一致性方案（TCC &amp; Saga &amp; MQ &amp; 本地消息表）TCC（Try-Confirm-Cancel）适用于高并发、低延迟的业务场景，例如支付系统。 Try（尝试执行）：进行业务检查，预留资源。 Confirm（确认执行）：若所有 Try 操作成功，则正式提交。 Cancel（取消执行）：若某个 Try 失败，则执行回滚操作。 注意： 需要业务开发者自己实现 Try、Confirm、Cancel 逻辑。 Confirm 失败时一般会重试，最终仍失败则需人工介入。 MQ 事务基于 两阶段提交，适用于 事件驱动架构。 发送半消息，等待本地事务执行。 本地事务执行成功，则确认发送消息；失败则回滚消息。 事务反查机制：检查消息是否成功发送。 消息消费失败时，消息队列会自动进行重试，超过最大次数进入 死信队列，等待人工处理。 特点： 适用于 跨系统事务（如支付完成后通知订单系统）。 异步处理，吞吐量高，但不保证强一致性。 Saga 事务适用于 长事务（如电商订单流程：支付 → 发货 → 确认收货）。 将事务拆分为 多个子事务，每个子事务执行完即提交。 若某个子事务失败，则触发 补偿事务 进行回滚。 Saga 事务没有预留资源，不保证隔离性。 Seata 是典型的 Saga 事务实现。 问题： 需要业务开发者自己编写补偿逻辑。 若补偿失败，则需人工介入。 本地消息表适用于 保证可靠消息的场景。 事务执行时，先写入数据库本地消息表。 定时扫描消息表，将消息投递到 MQ。 缺点：不支持事务回滚，需额外补偿机制。 方案对比总结 方案 业务代码侵入性 适用场景 关键特性 2PC 无侵入 传统数据库事务 强一致性，阻塞问题 3PC 无侵入 分布式数据库事务 改进 2PC，仍有不一致风险 TCC 需要开发者实现 高并发业务，如金融支付 高性能，需要 Try-Confirm-Cancel Saga 需要开发者实现 长事务，如订单流程 适用于多步骤事务，无隔离性 MQ 事务 依赖 MQ 事件驱动架构 事务解耦，不保证 ACID 本地消息表 依赖数据库 可靠消息 无法回滚，需要补偿 总结： 强一致性：2PC &#x2F; 3PC，适用于对事务要求极高的场景。 最终一致性：TCC &#x2F; Saga &#x2F; MQ &#x2F; 本地消息表，适用于高吞吐量或长事务。 TCC &#x2F; Saga 需要开发者手动管理事务，2PC &#x2F; 3PC 由事务管理器自动处理。 选择哪种方案，取决于业务需求、性能要求以及对一致性的容忍度。 &#x2F;&#x2F; 待补充学习 补充：分布式系统的开发中，延迟是个很重要的指标。评估服务可用性–&gt;负载均衡和容灾；评估领导者节点可用性–&gt;是否发起领导选举。 参考资料： 如何选择分布式事务解决方案？ 服务治理：分布式事务解决方案有哪些？ —某天职场老兵William突然抽查我的八股基础，回来赶紧灰溜溜补上……"},{"title":"【技术思考】工程上的最佳实践","path":"/2025/03/23/【技术思考】工程上的最佳实践/","content":"正式进入工作岗位之前对精进技术的思考——工程上的最佳实践 Why？首先要理解为什么要从工程实践的角度思考，常规的培训教程虽然是以项目的形式，但目的是帮助我们学会使用基本的开发工具如何使用，而实际开发过程中如何将各种技术组件有效地组合和应用、如何解决实际的业务问题，则是进一步需要关注的问题。 How？以原有的点评项目为例进行思考，可以考虑各部分设计的原因，能否优化： 消息中间件：思考使用场景，如订单状态更新、用户评价通知等，分析为什么要使用消息中间件，以及如何设计消息的生产、消费和存储。 缓存：考虑缓存的使用场景，如热门商品信息缓存、用户会话缓存等，分析如何识别并处理热key，以及缓存的更新和失效策略。 数据库设计与优化：审视数据库表的设计是否合理，是否符合业务需求，以及如何通过索引优化、查询优化等手段提升数据库性能。 微服务架构：分析拆分是否合理，服务之间的依赖关系是否清晰，服务降级、熔断和负载均衡策略是否有效。 服务上线：如何上线，例如灰度发布中的流量染色，如何保证服务的高可用性。 以微服务为例进行思考，考虑从调用和原理到设计决策的转变： 之前学习时，重点可能放在了如何调用中间件以及它们的底层原理上。 现在需要将重心转移到：在给定业务场景下，为什么要这样设计这些组件。 例如，微服务的负载均衡、服务发现、降级熔断等模块，不仅要清楚它们的作用，更要结合业务场景思考如何拆分微服务，以及制定相应的服务降级、熔断和负载均衡策略。以分布式事务为例，虽然有TCC、二阶段提交等理论方案，但在实际开发中，这些方案的严格实现需要很多条件支持，如数据库的兼容性、业务操作的反向接口等。在实际生产中，接口可能无法完美支持这些理论方案，这时需要考虑其他方法，如对账机制，来保证最终一致性，尤其是在对强一致性要求不高的业务场景中。以对账机制的工程实践为例，可能在实现最终一致性的时间间隔上较长，但其泛用性广且易于实现，设计对账机制需要考虑如何在业务执行频率较低时进行对照，以及如何处理幂等性等问题。 在上述思考过程中，可以借鉴大众点评、美团外卖、饿了么、滴滴等成熟项目的技术文章，了解它们在工程实践中的经验和教训。思路放宽，例如，各大应用基本都有点赞模块，了解它们是如何实现的，筛选出和自己的项目比较贴合的部分深入研究。 例如，大众点评在订单系统分库分表实践中的垂直切分和水平切分策略，以及如何通过Hash切分实现数据的均匀分布和易于扩展的架构。 DDD在大众点评交易系统演进中的应用 2-大众点评内容平台架构实践-三木 大众点评订单系统分库分表实践 了解了实践中的技术原理之后，再进一步关注通用方法论的提炼： 第一个是基础架构平台层面。例如，分布式ID发号器（如Leaf）、热Key检测与治理、大文件分布式对象存储（如JFS）等，理解这些通用实践，为自己的项目提供参考和借鉴，提升解决实际问题的能力。 第二个是思想层面。例如，在无法控制仓库报送数据的情况下，通过数据分析确定需要特殊处理的仓库，采用简单粗暴但有效的硬编码方式解决问题。此处提炼的方法论是：当技术手段难以直接解决问题时，可以通过分析实际数据和业务场景，找到变通的非技术性方法来绕过技术难题。 以上为主线任务，接下来是支线任务，即提前了解部门技术栈和业务后，例如云原生相关可以了解： Kubernetes稳定性保障实践 AutoMQ官方账号 —-与职场老兵William的对话整理"},{"title":"【通用工具】Git分布式版本控制工具","path":"/2025/03/21/【通用工具】Git分布式版本控制工具/","content":"Git有两个基本作用: 版本控制 团队开发 一、Git工作流程 二、Git基本配置设置用户信息设置：（+如果要查看，只输入双引号前面的就好了） 12git config --global user.name &quot;yourname&quot;git config --global user.email &quot;youremail&quot; 有3种范围：--local只对某个仓库有效，--global对当前用户的所有仓库有效，--system对系统所有登录的用户有效。 要显示config的配置，加--list。 三、Git基本使用获取本地仓库git init，执行之后工作目录下就会产生.git隐藏目录。 核心操作 clone（克隆）: 从远程仓库中克隆代码到本地仓库 checkout （检出）:从本地仓库中检出一个仓库分支然后进行修订 add（添加）: 在提交前先将代码提交到暂存区 可以接单个文件名，也可以接通配符 commit（提交）: 暂存区 –&gt; 本地仓库。本地仓库中保存修改的各个历史版本 可以接-m后跟注释 fetch (抓取) ： 从远程库，抓取到本地仓库，不进行任何的合并动作，一般操作比较少 pull (拉取) ： 从远程库拉到本地库，自动进行合并(merge)，然后放到到工作区，相当于fetch+merge push（推送） : 修改完成后，需要和团队成员共享代码时，将代码推送到远程仓库 辅助查看与操作 git status：查看修改的状态 git log [option]：查看提交日志，git-log以精简形式查看 git log：以默认形式查看提交日志 git log --all：显示所有分支的提交日志 git log --pretty=oneline：将提交信息显示为一行 git log --abbrev-commit：使得输出的 commitId 更简短 git log --graph：以图的形式显示提交历史，便于查看分支合并情况 git reflog commitID：记录所有操作，可以回滚到任意地方 git reset --hard commitID：版本回退 添加文件到忽略列表：创建 .gitignore 文件，列出要忽略的文件模式 回滚如果在开发过程中，某个需求不需要了，此时分为3种情况讨论： 文件在工作区：执行git checkout file 文件在暂存区：执行git reset HEAD file，让这个文件回到工作区，然后执行1 文件在本地仓库：执行git reset -方式（有3种） hard：工作区、暂存区、本地仓库3个地方保持一致 mixed：让文件保存在工作区 soft：让文件保存在暂存区 四、Git分支核心操作 查看本地分支：git branch 创建本地分支：git branch 分支名 切换分支：git checkout 分支名 可以直接切换到一个不存在的分支（创建并切换）：git checkout -b 分支名 合并分支：git merge 分支名称，一个分支上的提交可以合并到另一个分支 删除分支：不能删除当前分支，只能删除其他分支 git branch -d b1 删除分支时，需要做各种检查 git branch -D b1 不做任何检查，强制删除 解决冲突步骤： 处理文件中冲突的地方 将解决完冲突的文件加入暂存区(add) 提交到仓库(commit) GitFlow master （生产） 分支：线上分支，主分支，中小规模项目作为线上运行的应用对应的分支； develop（开发）分支：是从master创建的分支，一般作为开发部门的主要开发分支，如果没有其他并行开发不同期上线要求，都可以在此版本进行开发，阶段开发完成后，需要是合并到master分支,准备上线； feature/xxxx分支：从develop创建的分支，一般是同期并行开发，但不同期上线时创建的分支，分支上的研发任务完成后合并到develop分支； hotfix/xxxx分支：从master派生的分支，一般作为线上bug修复使用，修复完成后需要合并到master、test、develop分支； 还有一些其他分支，在此不再详述，例如test分支（用于代码测试）、pre分支（预上线分支）等等。 五、Git远程仓库基本命令 对接远程仓库： git remote add &lt;远端名称&gt; &lt;仓库路径&gt; 查看远程仓库： git remote 推送到远程仓库：git push [-f] [--set-upstream] [远端名称 [本地分支名]:[远端分支名]] 如果远程分支名和本地分支名称相同，则可以只写本地分支git push origin master -f 表示强制覆盖 --set-upstream 推送到远端的同时并且建立起和远端分支的关联关系 如果当前分支已经和远端分支关联，则可以省略分支名和远端名 查看本地分支与远程分支的关联关系：git branch -vv 从远程仓库克隆：git clone &lt;仓库路径&gt; [本地目录] 从远程仓库抓取&#x2F;拉取：（如果不指定远端名称和分支名，就抓取所有分支） git fetch [remote name] [branch name]：将仓库里的更新都抓取到本地，不进行合并。 git pull [remote name] [branch name]：将远端仓库的修改拉到本地并自动进行合并，等同于fetch+merge 解决冲突远程分支也是分支，解决冲突的方式和本地相同（看上文）。 需要先拉取远程仓库的提交，经过合并后才能推送到远端分支： 六、进阶命令交互式变基在本地使用，重新排序、合并、拆分、编辑或删除提交，从而整理提交历史，使其更加清晰。 rebase和merge的区别：都是实现合并分支，但是细节不同，rebase会把复杂的提交历史修订为干净整洁的线性结构，并且产生新的commitID。 使用步骤： 执行git rebase -i HEAD~5，此时打开一个编辑器，显示最近的5个提交，每个提交前有一个命令（默认是pick） 编辑提交列表，修改每一行前面的命令，例如pick改成reword Git会按照指令提交 常用命令： 命令 缩写 作用 pick p 保留该提交（不做修改） reword r 修改提交信息 edit e 暂停 rebase，允许修改提交内容（如增删文件）或提交信息 squash s 合并到前一个提交，并保留提交信息 fixup f 合并到前一个提交，但丢弃当前提交的提交信息 drop d 删除该提交 exec x 执行一个 shell 命令（如运行测试） 注意事项： 不要修改已经推送到远程仓库的提交历史（除非确定没有其他人基于此工作） 如果遇到冲突： 解决冲突后，用 git add 标记为已解决 继续 rebase：git rebase --continue 或终止 rebase：git rebase --abort 解决后强制推送到远程：git push --force 储藏 临时保存未提交的更改，将当前工作目录和暂存区的修改保存到一个“储藏区”（stash stack），可以快速切换分支或处理其他任务，后续再恢复这些更改。 基本命令： 基本命令 具体操作 说明 存（入栈） stash (push) 默认存入当前工作区的修改到栈中 stash save &quot;注释&quot; 可以连续存多次变动代码，添加注释方便区分 取（出栈） stash pop 取出栈顶的修改并应用到当前工作区，同时从栈中移除该修改 注意：确保此时 pop 的变动代码是你需要的，否则 pop 后可能需要重新压栈 stash apply 取出栈顶的修改并应用到当前工作区，但不从栈中移除该修改（类似 peek） 清除 stash drop 丢弃栈顶的修改 stash clear 清空整个 stash 栈 查看 stash list 查看 stash 栈中的所有修改记录 stash show + 栈索引 查看指定索引位置的修改详情 使用场景： 切换分支时，当前分支有未完成的代码。 需要紧急修复其他分支的 Bug，但不想提交当前代码。 临时保存实验性代码，避免污染提交历史。 合并冲突前，先保存当前改动。 使用示例： 12345678910111213141516# 1. 当前有未提交的修改，但需要切换到其他分支git stash# 2. 切换到其他分支并完成任务git checkout other-branch# ... 处理其他任务 ...# 3. 返回原分支并恢复储藏git checkout original-branchgit stash pop # 恢复并删除最近的储藏# 4. 查看储藏列表（可选）git stash list# 5. 清空储藏（可选）git stash clear 挑选工作在多分支结构的提交维度上，与merge的区别： merge：需要另一个分支上的所有变动 cherry-pick：需要另一个分支上的部分变动 提交情形： 当产生冲突时，会停下来让用户决定，此时有3种情况： --continue：解决冲突后，git add，再执行此命令继续合并 --abort：放弃合并，回到之前的状态 --quit：放弃合并，且不回到之前 比较不同diff命令，主要讲解两点提交和三点提交的区别： 七、铁令 切换分支前先提交本地的修改 代码及时提交，提交过了就不会丢 遇到任何问题都不要删除文件目录"},{"title":"【Go基础】环境搭建与开发","path":"/2025/03/19/【Go基础】环境搭建与开发/","content":"环境第1步:下载go（下载地址） 第2步：配置环境变量 GOROOT：go的安装目录 GOPATH：go的工作目录（全局），一般给文件夹起名叫GoWorkstation、Go_WorkSpace等。 src：存放源代码 pkg：存放依赖包 bin：存放可执行文件 GOPATH 是 Go 早期（Go 1.11 之前）管理依赖和项目代码的核心环境变量，早期go build、go run或go install等命令会按照当前目录-&gt;绝对路径-&gt;GOPATH路径查找目标代码。从Go 1.11开始，官方推荐使用Go Modules替代 GOPATH，可以在任意目录管理项目，依赖存储在 go.mod 和 go.sum，而非 GOPATH。 其他常用环境变量：GOOS，GOARCH，GOPROXY，国内用户建议设置 goproxy：export GOPROXY=https://goproxy.cn 开发推荐用Goland进行开发，实际运行的时候，如果是写的单独文件，设置按照file文件运行，否则包管理可能会有问题；如果是项目，需要指定目录为xxx/src，指定输出目录为xxx/bin。 Go Modules1. 创建Go Modules项目go mod init calc-mod：在当前目录初始化一个 Go Modules 项目。会创建 go.mod 文件，内容为module calc-mod，calc-mod 是自定义的模块名（通常用于本地开发）。 如果项目计划开源到 GitHub，模块名应改为仓库路径：go mod init github.com/fuxing-repo/fuxing-module-name，通常对应代码仓库的 URL（如 github.com/用户/仓库）。 生成的 go.mod： 1module github.com/fuxing-repo/fuxing-module-name 与 Maven&#x2F;Gradle 的区别：Go 的设计哲学是去中心化，直接通过代码仓库（GitHub&#x2F;GitLab 等）分发模块，依赖 Git Tag 版本化。 无需发布到中央仓库：Go 依赖直接从代码仓库（如 GitHub）下载。 版本控制：通过 Git 的标签（Tag）标记版本（如 v1.0.0）。如需指定版本运行 go get github.com/foo/bar@v1.2.3，Go 会自动更新 go.mod。 2. 完整流程示例步骤 1：初始化模块 1go mod init github.com/fuxing-repo/calculator 步骤 2：编写代码并导入依赖 在 main.go 中导入第三方库（如 github.com/gin-gonic/gin）： 12345678package mainimport &quot;github.com/gin-gonic/gin&quot;func main() &#123; r := gin.Default() r.Run()&#125; 步骤 3：自动下载依赖 运行任意 Go 命令（如 go build 或 go list）： 1go list Go 会： 解析 import 语句，发现依赖 github.com/gin-gonic/gin。 下载最新版本（或符合 go.mod 约束的版本）。 更新 go.mod 和 go.sum 文件。 包的管理Go的import是包级别的，包名就是当前文件夹名称。 一个项目中，可以存在一样的包名，如果需要引用同样的包名，可以用alisa区分。 可见性：无论是变量、函数还是类属性及方法，它们的可见性都是与包相关联的。如果属性名或方法名首字母大写，则可以在其他包中直接访问这些属性和方法，否则只能在包内访问。 结合import可以用一个包名来点出函数、结构体、接口等调用。 入口的package必须是main，否则可以编译成功，但是跑不起来。"},{"title":"【Go基础】错误处理","path":"/2025/03/19/【Go基础】错误处理/","content":"基本认识 在Go中，将错误当成值来进行处理，强调判断错误和处理错误，不支持try/catch捕获异常。 Go选择使用Error而非Exception来进行错误处理。 一般把错误作为函数或方法的最后一个返回值。 Error接口使用error接口表示错误类型。该接口只有一个Error()方法，返回描述错误信息的字符串。 123type error interface &#123; Error() string&#125; 接口类型的默认零值为nil，所以通常把调用函数时返回的错误和nil比较： 12345_, err := someFunc(some parameters)if err != nil&#123; fmt.Println(&quot;出现错误：&quot;, err) // 使用标准库fmt打印错误自动调用error类型的Error方法，打印错误描述信息 return&#125; Go这种机制的好处是，遇到error需要立即处理，而Java中是try/catch中包裹了一大堆代码，良性和致命的问题都会抛出错误，不容易排查问题。 创建错误由于error是接口，可以自定义错误类型（开发中间件使用较多）。 最简单的创建错误的方法是用errors包提供的New函数创建一个错误： 123func New(text string) error&#123; return &amp;errorString&#123;text&#125;\t// 返回一个指针，使得每次返回都是一个新的对象，否则在做等值判断时可能会出问题。&#125; 错误的两种类型error：可以被处理的错误；panic：非常严重不可恢复的错误。 errors包当需要传入格式化的错误描述信息，用fmt.Errorf更好，但是它提供很多描述错误的文本信息，会丢失原本的错误类型，导致错误在做等值判断时失效。为了解决这个缺陷，fmt.Errorf在1.13版本提供了特殊的格式化动词w%，可以基于已有错误再包装得到新的错误： 1fmt.Errorf(&quot;查询数据库失败，err:%w&quot;, err) 对于这种二次包装的错误，errors包提供了4个常用的方法： New：创建一个新的 error func Is(err, target error) bool ：判断err是否包含target，是不是特定的某个error func As(err error, target interface&#123;&#125;) bool：判断error是否为target类型，类型转换为特定的error（用得不多） func Unwrap(err error) error：获得error包含下一层错误，解除包装并返回被包装的 error 使用举例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport (\t&quot;errors&quot;\t&quot;fmt&quot;)func main() &#123;\tvar err error = &amp;MyError&#123;&#125;\tprintln(err.Error())\tErrorsPkg()&#125;type MyError struct &#123;&#125;func (m *MyError) Error() string &#123;\treturn &quot;Hello, it&#x27;s my error&quot;&#125;func ErrorsPkg() &#123;\terr := &amp;MyError&#123;&#125;\t// 使用 %w 占位符，返回的是一个新错误\t// wrappedErr 是一个新类型，fmt.wrapError\twrappedErr := fmt.Errorf(&quot;this is an wrapped error %w&quot;, err)\t// 再解出来\tif err == errors.Unwrap(wrappedErr) &#123; fmt.Println(&quot;unwrapped&quot;)\t&#125; if errors.Is(wrappedErr, err) &#123; // 虽然被包了一下，但是 Is 会逐层解除包装，判断是不是该错误 fmt.Println(&quot;wrapped is err&quot;)\t&#125;\tcopyErr := &amp;MyError&#123;&#125;\t// 这里尝试将 wrappedErr转换为 MyError\t// 注意我们使用了两次的取地址符号\tif errors.As(wrappedErr, &amp;copyErr) &#123; fmt.Println(&quot;convert error&quot;)\t&#125;&#125; panic意味着fatal error，调用者不能解决，彻底结束。可能遇到的场景： 调用别人的代码，别人没有合理使用panic（自己写代码还是用error）。 数组越界、不可恢复的环境、栈溢出等错误。 从panic中恢复： ​\trecover可以进行兜底，把这一次的request放弃，go的runtime会退出，可以去执行其他的request，但是风险比较大，revover一般就是记录个日志之类的，，示例： 123456789101112131415package mainimport &quot;fmt&quot;func main() &#123;\tdefer func() &#123; if data := recover(); data != nil &#123; fmt.Printf(&quot;hello, panic: %v &quot;, data) &#125; fmt.Println(&quot;恢复之后从这里继续执行&quot;)\t&#125;()\tpanic(&quot;Boom&quot;)\tfmt.Println(&quot;这里将不会执行下来&quot;)&#125; 使用原则 遇事不决选 error 当怀疑可以用 error 的时候，就说明不需要 panic 一般情况下，只有快速失败的过程，才会考虑panic defer用于在方法返回之前执行某些动作（类似于Java中的finally），一般用来释放资源（如锁等）。执行顺序：像栈一样，先进后出。 处理错误正常流程的代码推荐的写法，err处理缩进，正常的代码是一条直线。 12345678910111213/////////推荐写法////////f, err := os.Open(path)if err != nil &#123; // handle error&#125;// do stuff//////////不推荐///////f, err := os.Open(path)if err == nil &#123; // do stuff&#125;// handle error 少写if err !&#x3D; nil的技巧 返回err或者nil，可以直接return： 12345678910111213//////原来的写法func AuthenticateRequest(r *Request) error &#123; err := authenticate(r.User) if err != nil &#123; return err &#125; return nil&#125;//////推荐的写法 //毕竟函数的返回值就要error类型，而且调用函数之后就返回一个error类型，那直接return就好了func AuthenticateRequest(r *Request) error &#123; return authenticate(r.User)&#125; 用io.Reader统计读取内容的行数 1234567891011121314151617181920212223242526272829//////原来的写法func CountLines(r io.Reader) (int, error) &#123; var ( br = bufio.NewReader(r) lines int err error ) for &#123; _, err = br.ReadString(&#x27; &#x27;) lines++ if err != nil &#123; break &#125; &#125; if err != io.EOF &#123; return 0, err &#125; return lines, nil&#125;//////推荐的写法 //func CountLines(r io.Reader) (int, error) &#123; sc := bufio.NewScanner(r) lines := 0 for sc.Scan() &#123; lines++ &#125; return lines, sc.Err()&#125; 利用bufio.Scanner方法，这个里面封装了按行读取的逻辑，并且其Scan方法读取时遇到错误会记录下来，最终通过 sc.Err()统一返回。 包装错误类型，缓存错误 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758////////////原来的写法type Header struct &#123; Key, Value string&#125;type Status struct &#123; Code int Reason string&#125;func WriteResponse(w io.Writer, st Status, headers []Header, body io.Reader) error &#123; _, err := fmt.Fprintf(w, &quot;HTTP/1.1 %d %s\\r &quot;, st.Code, st.Reason) if err != nil &#123; return err &#125; for _, h := range headers &#123; _, err := fmt.Fprintf(w, &quot;%s: %s\\r &quot;, h.Key, h.Value) if err != nil &#123; return err &#125; &#125; if _, err := fmt.Fprintf(w, &quot;\\r &quot;); err != nil &#123; return err &#125; _, err = io.Copy(w, body) return err&#125;//////////////推荐的写法 //type errWriter struct &#123; io.Writer err error\t// 用来暂存&#125;func (e *errWriter) Write(buf []byte) (int, error) &#123; if e.err != nil &#123; return 0, e.err &#125; var n int n, e.err = e.Writer.Write(buf) return n, e.err&#125;func WriteResponse(w io.Writer, st Status, headers []Header, body io.Reader) error &#123; ew := &amp;errWriter&#123;Writer: w&#125; fmt.Fprintf(ew, &quot;HTTP/1.1 %d %s\\r &quot;, st.Code, st.Reason) for _, h := range headers &#123; fmt.Fprintf(ew, &quot;%s: %s\\r &quot;, h.Key, h.Value) &#125; fmt.Fprintf(ew, &quot;\\r &quot;) io.Copy(ew, body) return ew.err&#125; 下面这种写法，不用做任何err的判定，相当于在包装类里面复用了，更优雅。 使用errors包装错误-从根本上解决上一小节只是减少了if err !&#x3D; nil的数量，但是并没有从根本上解决不能提供详细上下文的问题。一方面，破坏原始错误，担心上层调用的人用做等值判定，只能一层层向上透传，最终输出没有堆栈没有上下文的信息，令人崩溃；另一方面，又想包装更多详细错误信息。 error.Wrap()：保留原始错误信息，捎带一些附加信息。 errors.Cause()：用来获取原始错误（根因，root error）。 errors.WithMessage()：不保存堆栈信息。 实际应用时： 自己的应用代码中，使用errors.New()或者errors.Errorf()返回错误； 如果调用其他包内的函数，直接返回，往上抛，不要在错误的地方到处打日志。（满足原则：只处理一次。） 如果使用三方库&#x2F;标准库，使用errors.Wrap()或errors.Wrapf()保存堆栈信息。 程序的顶部或者工作的goroutine顶部，用%+v详细记录堆栈。 处理错误的原则处理的原则是：如果遇到错误，只处理一次。 一些经常出现的错误代码，在错误处理中，既记录了日志，又返回了错误： 12345678func WriteAll(w io.Writer, buf []byte) error &#123; _, err := w.Write(buf) if err != nil &#123; log.Println(&quot;unable to write:&quot;, err) return err &#125; return nil&#125; 这个时候又尬住了，一方面，不记录日志，找不到是谁报错；另一方面，记录日志接下来调用者层层打印，在控制台的输出可能就层层割裂，没有完整的堆栈信息。 继续讲处理的原则：错误处理契约规定，出现错误时，不能对其他返回值的内容做任何假设。如果程序员忘记return，函数返回的结果可能是正确的，但是其他返回值的内容是错误的。 那么应该如何记录日志？原则： 错误要被日志记录 *应用程序处理错误，保证**100%*完整性 之后不再报告当前错误 结合上一小节，包装错误的原则： 如果你提供的库很多人使用，不应该使用任何wrap包装错误 如果你的函数无法处理错误，携带足够多的上下文，用wrap.Errors往上抛（足够的上下文：能帮助解决问题，一般是什么人调用了什么接口，返回成功还是失败） 如果这个错误被处理过，就不要再抛了。 【参考资料】 https://www.liwenzhou.com/posts/Go/error/"},{"title":"【Go基础】并发编程基本概念","path":"/2025/03/19/【Go基础】并发编程基本概念/","content":"并发编程基本概念串行、并发与并行 串行：我们都是先读小学，小学毕业后再读初中，读完初中再读高中。 并发：同一时间段内执行多个任务（你在用微信和两个女朋友聊天）。 并行：同一时刻执行多个任务（你和你朋友都在用微信和女朋友聊天）。 进程、线程和协程 进程（process）：程序在操作系统中的一次执行过程，系统进行资源分配和调度的一个独立单位。 线程（thread）：操作系统基于进程开启的轻量级进程，是操作系统调度执行的最小单位。 协程（coroutine）：非操作系统提供而是由用户自行创建和控制的用户态‘线程’，比线程更轻量级。 并发模型4种常见的实现方式： 线程&amp;锁模型 Actor模型 CSP模型（communicating sequential processes，Go中主要是基于CSP的goroutine和channel实现） Fork&amp;Join模型"},{"title":"【Go基础】垃圾回收演进 三色标记法","path":"/2025/03/19/【Go基础】垃圾回收演进三色标记法/","content":"GO1.3标记清除，整体需要STW：1.暂停，找到可达和不可达对象，2. 标记可达对象，3. 清除未标记对象，4. 结束暂停 GO1.5三色标记法，堆启动写屏障，栈不启动，全部扫描一次后，需要重新扫描栈（STW），效率低 如果没有STW，对象丢失的2个条件： 黑色对象指向白色对象（白色挂在黑色下面） 灰色对象与其可达白色对象之间遭到破坏（灰色也丢失了该白色） 屏障机制，保障对象不丢失的2种方式： 强三色不变式：不允许黑色对象指向白色对象 弱三色不变式：允许黑色对象指向白色对象，但是该白色对象要被灰色对象可达 为此，go初步得到两种屏障方式： 插入写屏障：只使用在堆中，将黑色指向的白色对象标记为灰色；栈要启动STW重新三色标记扫描（仍然需要STW重新扫描栈） 删除写屏障：被删除的白色节点标记为灰色（保护灰色对象到白色对象的路径不会断），所以最后一个指向它的指针也依旧可以活过这一轮，在下一轮GC中被清理掉（回收精度低，开始时STW记录初始快照） 为什么在栈中不使用： GO1.8三色标记法，混合写屏障，栈不启动，堆启动，几乎不需要STW，效率高 结合得到混合写屏障（满足弱三色不变）： 开始时将所有栈上的可达节点标记为黑色，在GC期间栈上新增的也标记为黑色（无需STW） 删除和新增的全部标记为灰色 参考资料： https://www.bilibili.com/video/BV1wz4y1y7Kd/"},{"title":"【Go基础】Go入门与实践资源帖","path":"/2025/03/19/【Go基础】Go入门与实践资源帖/","content":"看到好的持续更新…… Go系统教程 从语法讲起：李文周博客 七天快速上手项目 Go测试驱动开发博客 孔令飞项目开发实战课程，孔令飞图文教程 《Go 语言高级编程》书籍 Go算法刷题模板 Go实战项目 KV系统 crawlab分布式爬虫平台 seaweedfs分布式文件系统 Cloudreve云盘系统 gfast后台管理系统（基于Go Frame） alist多存储文件列表（基于Gin、React） Yearning开源SQL审核平台 Go要点 GMP机制 并发编程机制 编辑解释运行机制 GC机制 看过的帖子 腾讯技术工程：协程调度的本质 通用技术面试相关 极客时间面试指导视频课"},{"title":"【Go基础】微服务概念与演进","path":"/2025/03/19/【Go基础】微服务概念与演进/","content":"微服务概念与演进巨石架构到微服务的演进传统网页应用虽然进行了模块化设计，但是最终仍然是打包成一个war包进行部署，启动慢，无法拓展，可靠性很低。 什么是微服务是面向服务的架构模式（SOA）的最佳实践。定义：围绕业务功能构建的，服务关注单一业务，服务间采用轻量级的通信机制，可以全自动独立部署，可以使用不同的编程语言和数据存储技术。微服务架构通过业务拆分实现服务组件化，通过组件组合快速开发系统，业务单一的服务组件又可以独立部署，使得整个系统变得清晰灵活。 如何实现微服务组件服务化，例如在Go中实现需要：• kit：一个微服务的基础库（框架）• service：业务代码 + kit 依赖 + 第三方依赖组成的业务微服务• RPC + message queue：轻量级通讯按业务组织服务，常见的模式：大前端（移动&#x2F;Web） &gt; 网关接入 &gt; 业务服务 &gt; 平台服务 &gt; 基础设施（PaaS&#x2F;Saas） 微服务的优点和缺点优点：原子服务、独立进程、隔离部署、去中心化服务治理。 缺点：基础设施的建设、复杂度高。固有的复杂性：① 必须使用RPC或者消息传递实现进程间的通信，处理通信慢与局部失效的问题；② 不同服务可能使用不同数据库。 要搞定这些缺点，需要做怎样的基础设施建设做什么事情–可用性设计、API设计等引申话题 微服务组件微服务设计中常见的角色三大组件：API Gateway、BFF层、底层服务Microservices。API网关分层： 流量入口：协议转换&#x2F;路由分发 安全边界：统一认证&#x2F;权限控制 流量治理：限流熔断&#x2F;日志监控 BFF适配层：为不同终端提供定制化APICQRS模式：读写分离（通过binlog实现数据同步） 演进过程Microservices拆分: 按垂直功能性能角度，含久必分分久必合 可以考虑中间加一层(例如统一接入账号) 按照业务领域抽象（DDD） 按照功能拆分：CQRS，应用程序分为命令端和查询端。 安全问题外部的安全保障：API Gateway统一认证拦截 -&gt; BFF校验Token -&gt; Service 服务内部的安全保障：① 认证：知道是谁调用的；② 授权：RBAC，控制能访问哪些接口。 信任等级：Full&#x2F;Half&#x2F;Zero Trust。 gRPC概念A high-performance, open-source universal RPC framework. 高性能开源框架。特性： 支持多语言； 序列化支持Protocol Buffer和Json； HTTP&#x2F;2多路复用。 其中最重要的是标准健康监测协议，应用如下：应用1：服务稳定与不稳定时摘除与恢复；应用2：外挂容器健康检测；应用3：生产者与消费者之间的检测；应用4：平滑发布。 服务发现的模型① 客户端发现（微服务的核心是去中心化，用这种更好）；② 服务端发现（如果服务很大，可能用service mesh）。 多集群与多租户多集群why?——单集群坏处：一般布N+2来冗余节点。出现故障时后果严重。how?——物理上两套资源，逻辑上维护cluster概念。好处？——不同集群使用多套独占的缓存，性能好。坏处？——缓存命中率下降，不同业务形态数据正交。拓展：从全集群中选取一批节点（子集），利用划分子集限制连接池大小。——子集算法。 多租户why？保障代码隔离性，基于流量租户做路由决策。问题：[并行测试]时混用环境不可靠，而多布环境成本高，也难以做压测。解决方法：染色发布，基于流量类型做路由。本质是从源头传递一个标签，挂在go的上下文中，基于RPC负载均衡的流量做路由,路由到指定的节点。 参考资料：https://microservices.io/index.htmlhttps://blog.csdn.net/mindfloating/article/details/51221780https://www.cnblogs.com/dadadechengzi/p/9373069.htmlhttps://www.cnblogs.com/viaiu/archive/2018/11/24/10011376.htmlhttps://www.cnblogs.com/lfs2640666960/p/9543096.htmlhttps://mp.weixin.qq.com/s/L6OKJK1ev1FyVDu03CQ0OAhttps://www.bookstack.cn/read/API-design-guide/API-design-guide-02-面向资源的设计.mdhttps://www.programmableweb.com/news/how-to-design-great-apis-api-first-design-and-raml/how-to/2015/07/10http://www.dockone.io/article/394https://www.jianshu.com/p/3c7a0e81451ahttps://www.jianshu.com/p/6e539caf662dhttps://my.oschina.net/CraneHe/blog/70317https://my.oschina.net/CraneHe/blog/703169https://my.oschina.net/CraneHe/blog/703160 学习笔记，侵删。"},{"title":"【LeeCode】刷题记录.md","path":"/2024/04/08/【LeeCode】刷题记录/","content":"作者：力扣官方题解 来源：力扣（LeetCode） LeeCode热题10049、字母异位词分组（中）https://leetcode.cn/problems/group-anagrams/solutions/520469/zi-mu-yi-wei-ci-fen-zu-by-leetcode-solut-gyoc/ 题面给你一个字符串数组，请你将 字母异位词 组合在一起。可以按任意顺序返回结果列表。 字母异位词 是由重新排列源单词的所有字母得到的一个新单词。 为什么是哈希表相关的题？ 思路： 当把单词中所有字母按照字母顺序表排列时，字母异位词的排序后的单词是相同的。 可以使用相同点作为一组字母异位词的标志，使用哈希表存储每一组字母异位词。 哈希表的键为一组字母异位词的标志，哈希表的值为一组字母异位词列表。 具体做法：遍历每个字符串，对于每个字符串，得到该字符串所在的一组字母异位词的标志，将当前字符串加入该组字母异位词的列表中。遍历全部字符串之后，哈希表中的每个键值对即为一组字母异位词。 方法1：字母排序 构造单词的字符排序，作为键。 将单词加入散列表。 返回答案。 1234567891011121314class Solution &#123; public List&lt;List&lt;String&gt;&gt; groupAnagrams(String[] strs) &#123; Map&lt;String, List&lt;String&gt;&gt; map = new HashMap&lt;String, List&lt;String&gt;&gt;(); for (String str : strs) &#123; char[] array = str.toCharArray(); Arrays.sort(array); String key = new String(array); List&lt;String&gt; list = map.getOrDefault(key, new ArrayList&lt;String&gt;()); list.add(str); map.put(key, list); &#125; return new ArrayList&lt;List&lt;String&gt;&gt;(map.values()); &#125;&#125; 复习 char[] toCharArray() 。将此字符串转换为新的字符数组。 getOrDefault。HashMap的一个方法，返回指定键映射到的值，如果此映射不包含键的映射，则返回 defaultValue 。 向list中新增元素用add方法。 向哈希表中新增元素用put方法，同时传入键和值。 复杂度分析 方法2：计数 互为字母异位词的两个字符串包含的字母相同，因此两个字符串中的相同字母出现的次数一定是相同的，故可以将每个字母出现的次数使用字符串表示，作为哈希表的键。 字符串只包含小写字母，因此对于每个字符串，可以使用长度为 26 的数组记录每个字母出现的次数。 首先统计字符的出现顺序，然后构造键，把具有相通特征的字符串的单词们放在一组，最后返回结果。 12345678910111213141516171819202122232425class Solution &#123; public List&lt;List&lt;String&gt;&gt; groupAnagrams(String[] strs) &#123; Map&lt;String, List&lt;String&gt;&gt; map = new HashMap&lt;String, List&lt;String&gt;&gt;(); for (String str : strs) &#123; int[] counts = new int[26]; int length = str.length(); for (int i = 0; i &lt; length; i++) &#123; counts[str.charAt(i) - &#x27;a&#x27;]++; &#125; // 将每个出现次数大于 0 的字母和出现次数按顺序拼接成字符串，作为哈希表的键 StringBuffer sb = new StringBuffer(); //可变字符串对象 for (int i = 0; i &lt; 26; i++) &#123; if (counts[i] != 0) &#123; sb.append((char) (&#x27;a&#x27; + i)); sb.append(counts[i]); &#125; &#125; String key = sb.toString(); List&lt;String&gt; list = map.getOrDefault(key, new ArrayList&lt;String&gt;()); list.add(str); map.put(key, list); &#125; return new ArrayList&lt;List&lt;String&gt;&gt;(map.values()); &#125;&#125; 复杂度分析 面试要点 通过分析，能否意识到单词和键的映射关系。 利用散列表高效储存结果。 数据结构和常见的库函数。"},{"title":"【资源帖】学习Java和算法","path":"/2024/04/06/【资源帖】学习Java和算法/","content":"Java教程学习路线【黑马程序员】 Java简版基础教程：https://www.bilibili.com/video/BV1Cv411372m/ 书：《Java核心技术 1》 书：《Head First Java》 Java Web框架：https://www.bilibili.com/video/BV1m84y1w7Tb/ 单体项目开发： 苍穹外卖：https://www.bilibili.com/video/BV1TP411v7v6/ 微服务： 全套微服务技术栈：https://www.bilibili.com/video/BV1S142197x7/ 企业级项目实战（选择学习）： 学成在线【在线教育】：https://www.bilibili.com/video/BV1j8411N7Bm/ 黑马头条【企业级微服务项目】 ：https://www.bilibili.com/video/BV1Qs4y1v7x4/ 面试专题： 2023版：https://www.bilibili.com/video/BV1yT411H7YK/ 复制标题和时长：https://www.bilibili.com/read/cv22846057/ 精进指南 （JavaWeb后，选学）MySQL：https://www.bilibili.com/video/BV1Kr4y1i7ru/ （微服务后，选学）Redis微服务：https://www.bilibili.com/video/BV1cr4y1671t/ （微服务后，选学）MybatisPlus：https://www.bilibili.com/video/BV1Xu411A7tL/ （JVM前，必学）计算机网络：https://www.bilibili.com/video/BV1c4411d7jb/ （Java基础，选学）JVM虚拟机：https://www.bilibili.com/video/BV1r94y1b7eS/ （JVM后，选学）并发编程：https://www.bilibili.com/video/BV16J411h7Rd/ （git版本控制，选学）https://www.bilibili.com/video/BV1MU4y1Y7h5/ 资源帖 JavaGuide：JavaGuide（Java学习&amp;面试指南） | JavaGuide JavaBooks：https://gitee.com/itwanger/JavaBooks 拿个offer：拿个offer - 开源&amp;项目实战 (nageoffer.com) LeeCode刷题指南官网力扣 (LeetCode) 全球极客挚爱的技术成长平台 刷题指北peach买个共享会员账号看考察频次。 资源帖 labuladong：本站简介 | labuladong 的算法笔记（提升算法能力。） 代码随想录：代码随想录 (programmercarl.com)（全面，但是精简，适合面试突击。） 小林coding：小林coding (xiaolincoding.com)（图解好理解，但只有Redis、MySQL、计网。） 左程云：左程云的个人空间-左程云个人主页-哔哩哔哩视频 (bilibili.com)（算法讲解。） NeeCode：NeetCode（英文站点。） 推荐书单 《剑指offer》。"},{"title":"【求职】如何写一份受欢迎的校招简历","path":"/2024/04/05/【求职】如何写一份受欢迎的校招简历/","content":"常见问题 过度包装设计。减弱主要信息能量，华而不实。 篇幅过长。 求职定位不明。 实践经历描述不当。 一份简历闯天下。 JD：工作职责、工作胜任力。 使用表格式简历。 啰啰嗦嗦重点不突出。 不该讲的乱讲。例如，创业、离职原因、到岗时间、离婚、错误检讨、薪资条件。 优秀简历的特征版面设计简洁大方、布局清晰、模板分界。 简历结构结构完整、详略得当、易于阅读。 内容呈现逻辑清晰、优势突出、数据支撑。 人岗匹配有的放矢、贴近岗位JD、天生我才。 效果 脱颖而出、入得法眼。 顺畅读完，越读越喜欢。 打动人心，不如见一面。 为面试好印象做好铺垫。（面试官其实是根据初印象，步步求证是否确实是需要的人。） 简历的完整结构“2+2”通用的（非本专业&#x2F;技术岗）： 基本信息：略写。7%。 自我评价：较详。20%。 工作经历：详写。（大力气。）70%。 学历、证书、技能：略写。3%。 基本信息 姓名+求职意向+性别+年龄。（政治面貌：国企央企等写，外企不写，民企无所谓。） 联系方式：城市、电话、微信、邮箱。（不用写太多。城市可以写XX(意向城市)。联系方式三个必有一，推荐电话。） 个人照片：彩色、正面头像、有精气神。（匹配行业。） 自我评价&#x2F;教育背景社招： 工作背景。例如，年份+领域&#x2F;行业+擅长&#x2F;熟悉&#x2F;掌握。 优势能力。四条分号隔开。专业软件可以写。 职业素养。 校招： 起止时段：学校、专业、学历、学位。 主修课程。 奖学金可以写。 工作经历&#x2F;实习经历&#x2F;项目经历社招： 工作时段。（可以有总分，总的在某个公司，分的是不同岗位。最好是倒叙。） 工作职责。（前3-5个。） 工作业绩。（为了醒目，可以换个标志，比如五角星。一定要有数据，没数据也不要乱讲。） 工作获奖。（要有含金量的，行业、省市级以上，发明专利等。） 校招： 起止时段、公司、岗位。 工作职责、价值、奖项。 其他佐证 学历背景：学校、专业。 语言能力：语种、级别。（只是针对某些需要语言能力的岗位。其他：听说读写能力流利，可作为工作语言。） 专业技能：证书、级别。（例如岗位资格证。） 校招和社招的区别 教育背景前置&#x2F;后置。 自我评价的有无。（复盘能力。） 优秀简历写作心法人岗匹配！！！ 职场的本质是价值交换。（以终为始。） 见字如面，格式细节很重要，大小标题和逻辑关系。 凤头猪肚豹尾。自我评价漂亮客观，工作经历饱满有结果，其他佐证简短有力。 工作经历倒叙。写清楚总分，闭环表达，数据支撑。 工作年限5年以下，请用一张A4纸完成。 如果经历比较少，根据一段经历可以多挖掘，例如，“1+3+6+x”主轴。 如何准备 确定自己身份：校招&#x2F;社招，确定目标岗位，了解岗位JD。 准备模板，通读三遍。准备素材，多多益善。（所有经历都可以准备。） 现有骨架，再填充。时间倒叙，先粗后细。 先写草稿，反复打磨。"}]